import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as t,o as r,c as o,a as e,b as l,d as n,f as a,e as i}from"./app-6Cgy3eAt.js";const d={},c={href:"https://tech.meituan.com/2014/06/30/mysql-index.html",target:"_blank",rel:"noopener noreferrer"},E=i(`<h3 id="mysql-知识点" tabindex="-1"><a class="header-anchor" href="#mysql-知识点"><span>mysql 知识点</span></a></h3><h4 id="基础部分" tabindex="-1"><a class="header-anchor" href="#基础部分"><span>基础部分</span></a></h4><ol><li><p>drop、truncate、 delete区别</p><p>1.DROP TABLE • 作用：这个命令彻底删除整个表，包括表结构、所有数据、索引和权限等。 • 特点：执行速度快，因为不需要逐行删除数据，也无法回滚。 • 使用场景：当你不再需要一个表及其所有相关数据和结构时。</p><p>2.TRUNCATE TABLE • 作用：删除表中的所有数据，保留表结构。 • 特点： • 执行速度快，类似于DROP，因为它重新创建了表并放弃了所有数据，而无需记录每一行的删除操作。 • 自动提交事务，不可回滚。 • 重置自增列（如果有的话）回到初始值 • 使用场景：当你需要清空表的所有数据，但还想保留表结构时。</p><p>3.DELETE • 作用：删除表中的数据，可以选择性地删除满足特定条件的行。 • 特点： • 可以带条件执行，只删除满足条件的记录。 • 消耗资源较多，特别是数据量大时，因为它需要记录每一条被删除的记录，以便事务可以回滚。 • 可以回滚，是事务安全的。 • 使用场景：当你需要删除表中一部分数据，并且希望这个操作是可逆的（通过事务回滚）时。</p></li><li><p>简单总结数据库三范式是什么? 数据库三范式是设计规范，确保数据高效、无冗余： 1.第一范式：确保每列不可分，数据原子性。 2.第二范式：非主键列依赖整个主键。 3.第三范式：非主键列间相互独立，无传递依赖。</p></li><li><p>解释数据库反范式化</p><p>数据库反范式化是针对数据库规范化的一种设计策略，它通过有意地引入数据冗余、重复的字段或 denormalization 来优化特定的查询性能或简化数据访问</p><p>1.提升查询速度：通过在表中加入冗余数据，可以避免复杂的联接操作，使得查询只需在一个表中完成，从而减少查询时间和提高效率。 2.简化应用程序代码：应用程序可能无需执行多表联查就能获取所需的所有数据，这可以减少代码复杂度并提高开发效率。 3.减少磁盘I/O操作：通过预先计算并存储汇总数据（如计数、总和等），可以减少运行时的计算负担和磁盘读取次数。</p></li><li><p>union和union all有什么不同?</p><p>UNION 和 UNION ALL 都是用来合并两个或多个SELECT语句的结果集，但它们之间存在一个关键的区别： • 列数和数据类型必须相同：UNION 合并的每个查询，必须返回相同数量的列，且每列的数据类型必须相同或兼容。 • UNION: 会去除结果集中的重复行。在返回结果前，它会对所有结果集进行排序并合并，同时消除完全相同的行。 这个过程需要进行排序操作，因此如果数据量大，可能会比较耗时。 • UNION ALL: 不会去除重复行。它直接将各个SELECT语句的结果合并在一起，不做去重处理。 因此，如果源数据中有重复行，在结果集中也会显示出来。由于省去了去重和排序的过程，UNION ALL通常比UNION效率更高。</p><p>总结来说，如果你需要合并的结果集中不包含重复行，应该使用UNION；如果你不在乎结果集中是否有重复行，并且追求更高的查询效率，应选择UNION ALL。</p></li><li><p>SQL语句执行顺序</p><p>下面是标准的SQL查询（主要是指SELECT语句）执行的大致步骤，需要注意的是，不同的数据库系统可能有细微差异，但基本遵循以下顺序：</p><ol><li>FROM: 首先，确定查询涉及的表。如果有多个表通过JOIN连接，这一步也会解析JOIN条件。</li><li>ON: 处理JOIN子句中的条件，确定如何连接表。</li><li>WHERE: 应用WHERE子句中的条件，过滤不符合条件的行。</li><li>GROUP BY: 将结果集按照GROUP BY子句中的列进行分组。</li><li>HAVING: 对GROUP BY后的结果应用HAVING子句中的条件，进一步过滤分组。</li><li>SELECT: 此时处理SELECT列表，计算所有的列表达式。</li><li>DISTINCT: 如果SELECT语句中包含了DISTINCT关键字，这时会去除重复的行。</li><li>ORDER BY: 根据ORDER BY子句中的列对结果集进行排序。</li><li>LIMIT/TOP: 如果语句中有限制返回行数的子句（如MySQL的LIMIT或SQL Server的TOP），此时会应用这些限制。</li><li>OFFSET/FETCH: 在某些数据库中（如SQL Server的OFFSET-FETCH或MySQL的LIMIT OFFSET），还会在此步处理分页查询。 记住，这个顺序是一个逻辑上的概念，实际的数据库引擎内部可能采用更优化的方式来执行查询，不一定严格按这个顺序进行。但理解这个逻辑有助于我们编写更有效的SQL语句。</li></ol></li><li><p>null的含义</p><p>在SQL中，NULL值表示一个不确定的或者未知的数据。它与空字符串、零或任何其他值都不相同。以下几点详细解释了NULL的含义： • 缺失数据: NULL常用来表示数据表中的某个字段没有值或者值未知。这与字段为空字符串或数值0有本质区别，因为空字符串和0都是具体的值，而NULL则表示“没有值”。 • 三值逻辑: SQL支持TRUE、FALSE以及UNKNOWN（由NULL代表）的三值逻辑。这意味着在比较操作中，任何涉及NULL的比较（如=, !=, &lt;, &gt;等）都会返回UNKNOWN， 除非使用IS NULL或IS NOT NULL来明确测试NULL值。 • 集合运算: 在UNION操作中，NULL值会被视为相等，即使它们来自不同的源。 • 聚合函数: NULL值在计算如COUNT, AVG, SUM等聚合函数时通常会被忽略，但COUNT(*) 会包括NULL值。 简而言之，NULL是SQL中一种特殊的标记，用来表示未知或不可用的信息，它在处理查询时有着特殊的规则。</p></li></ol><p>7.索引的类型, 建索引的原则</p><pre><code>物理存储角度
- 聚簇索引
- 非聚簇索引，也叫辅助索引

数据结构角度
- B+数索引
- Hash索引
- 全文索引（5.6之前仅在存储引擎为MyISam时可以）
- R-tree索引

逻辑角度
- 主键索引：是一种唯一索引，不允许空值
- 单列索引：每个索引只能包含单个列，一个表中可以多个单列索引
- 组合索引：每个索引至少包含2个列字段，查询服从最左分配原则
- 唯一索引：增加此索引的列在表中的值必须唯一
- 空间索引：针对空间列字段加的索引

索引的类型主要有以下几种：

1. 单一索引(Single Index): 只基于单个列创建的索引。
2. 复合索引(Composite Index): 基于多列创建的索引。复合索引的列顺序会影响其效率，因为数据库会优先考虑索引的最左前缀原则。
3. 唯一索引(Unique Index): 确保索引列中的值是唯一的。如果试图插入重复的值，数据库将阻止该操作或返回错误。
4. 主键索引(PRIMARY KEY Index): 一种特殊的唯一索引，用于标识表中的每一行记录。一张表只能有一个主键索引。
5. 全文索引(Full-text Index): 用于全文搜索，可以高效地处理LIKE操作符以及复杂的文本搜索请求。
6. 空间索引(Spatial Index): 用于地理位置和几何数据类型的索引，如点、线、面等。
7. 位图索引(Bitmap Index): 在数据仓库等场景下使用较多，适用于低基数（值的种类少）的列，能有效压缩存储空间并提高查询速度。

建索引的原则包括：

1. 频繁查询的列: 经常出现在WHERE子句中的列应被考虑建立索引。
2. 区分度高: 列的值分布要尽量广泛，避免大量重复值的列上建索引，因为这样索引的效率会降低。
3. 索引选择性: 选择性高的索引更有用，即索引列中不同值的数量与表中总行数的比例要高。
4. 考虑查询代价: 索引可以加速查询，但会占用额外的磁盘空间，且在插入、删除、更新操作时需要维护索引，可能会增加这些操作的成本。
5. 复合索引策略: 在创建复合索引时，考虑查询中经常一起出现的列，并将最常用作筛选条件的列放在前面。
6. 避免过度索引: 过多的索引会占用更多的存储空间，影响写操作性能，选择最有效的索引至关重要。
7. 避免为小表建索引

总结： 索引类型：常用的包括普通索引、唯一索引、主键索引、组合索引、全文索引等。 
建索引的原则：选择合适的列、避免频繁更新的列、为唯一性高的列创建索引、组合索引的顺序很重要、避免过多索引、避免为小表创建索引。
</code></pre><ol start="8"><li><p>MySQL InnoDB、Mysaim的特点？</p><ol><li>InnoDB 的特点 InnoDB 是 MySQL 的默认存储引擎，提供了许多高级功能，尤其在数据完整性和高并发场景下表现优异。</li></ol><p>主要特点： 事务支持：InnoDB 是支持 ACID（原子性、一致性、隔离性、持久性）事务的存储引擎，支持 COMMIT、ROLLBACK 和 SAVEPOINT 操作。 这意味着它适合那些对数据一致性要求较高的应用，比如金融系统。</p><p>行级锁（Row-level Locking）：InnoDB 使用行级锁定，意味着每次修改的只是一行数据，而不是整张表。 相较于 MyISAM 的表级锁，这显著提升了高并发写入场景的性能。</p><p>外键支持：InnoDB支持外键约束，允许设置外键以维护表之间的引用完整性，这对于需要保持数据完整性的系统非常有用。</p><p>崩溃恢复能力：InnoDB 采用 Redo Log 和 Undo Log 来确保在崩溃或停电时数据的完整性。通过这些日志，InnoDB能够在数据库崩溃后进行自动恢复。</p><p>聚簇索引（Clustered Index）：InnoDB 使用聚簇索引存储数据。这意味着数据和索引存储在一起，主键索引同时也是数据的物理存储顺序。因此，基于主键的查询效率会更高。</p><p>性能优化：InnoDB 具有良好的读写性能，尤其适合高并发的在线事务处理（OLTP）系统。</p><p>适用场景： 需要事务支持的系统，如金融系统、银行系统。 高并发写入操作频繁的场景。 需要维护数据一致性和完整性的系统。 需要使用外键的复杂数据库设计。</p><ol start="2"><li>MyISAM 的特点 MyISAM 是 InnoDB 之前 MySQL 默认的存储引擎，适用于轻量级的数据库应用，主要特点是简单、快速，但功能不如 InnoDB 完善。</li></ol><p>主要特点： 无事务支持：MyISAM 不支持事务处理。如果应用需要事务支持，比如回滚、提交操作，那么 MyISAM 并不适合。 表级锁（Table-level Locking）：MyISAM 采用表级锁定，这意味着当一条记录被更新时， 整个表会被锁定，其他的写操作必须等待。虽然对于读取较多、写入较少的场景表现良好，但在高并发写入操作下，MyISAM 的性能会受到限制。</p><p>没有外键支持：MyISAM 不支持外键约束，因此数据表之间的引用完整性必须通过应用程序来维护。 更高的读取性能：由于 MyISAM 的结构相对简单，它的读操作性能往往优于 InnoDB。对于读多写少的应用，它可能更具优势。 表和索引分开存储：MyISAM 将表和索引分开存储，表以 .MYD 文件格式存储，索引以 .MYI 文件格式存储。这使得它的表格空间管理比 InnoDB 更为简单。 全文索引（Full-text Indexing）：MyISAM 在早期版本中就支持全文索引（在 InnoDB 5.6 之前，只有 MyISAM 提供全文索引），这使它适合一些需要文本搜索的应用。</p><p>适用场景： 读多写少的系统，比如博客、新闻站点等，尤其是大部分操作是读取而不是更新。 数据一致性要求不高的场景。 不需要事务或外键支持的应用。 对于快速查询和文本搜索有较高要求的应用</p></li><li><p>myisam与innodb的区别</p><ul><li>InnoDB支持事物，而MyISAM不支持事物</li><li>InnoDB支持行级锁，而MyISAM支持表级锁</li><li>InnoDB支持MVCC, 而MyISAM不支持</li><li>InnoDB支持外键，而MyISAM不支持</li><li>InnoDB不支持全文索引，而MyISAM支持。</li></ul></li><li><p>Mysql8.0自带哪些存储引擎？分别是做什么的？</p></li></ol><p>1.InnoDB存储引擎</p><p>InnoDB是MySQL的默认事务型引擎，它被设计用来 处理大量的短期(short-lived)事务 。可以确保 事务的完整提交(Commit)和回滚(Rollback)。 除非有非常特别的原因需要使用其他的存储引擎，否则 应该优先考虑InnoDB引擎 。 数据文件结构： 表名.frm 存储表结构（MySQL8.0时，合并在表名.ibd中） 表名.ibd 存储数据和索引</p><p>InnoDB不仅缓存索引还要缓存真实数据， 对内存要求较 高 ，而且内存大小对性能有决定性的影 响。</p><ol start="2"><li>MyISAM存储引擎</li></ol><p>MyISAM提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等，但 MyISAM不支持事务和行级 锁 ，有一个毫无疑问的缺陷就是崩溃后无法安全恢复。 优势是访问的 速度快 ，对事务完整性没有要求或者以SELECT、INSERT为主的应用。 数据文件结构： 表名.frm 存储表结构 表名.MYD 存储数据 表名.MYI 存储索引</p><p>SHOW VARIABLES LIKE &#39;%default_storage_engine%&#39;; MyISAM只缓存索引，不缓存真实数据。</p><ol start="3"><li>Archive引擎</li></ol><p>Archive档案存储引擎只支持INSERT和SELECT操作 。</p><p>Archive表适合日志和数据采集（档案）类应用。 根据英文的测试结论来看，Archive表比MyISAM表要小大约75%，比支持事务处理的InnoDB表小 大约83%。</p><ol start="4"><li>Blackhole引擎</li></ol><p>Blackhole引擎没有实现任何存储机制，它会丢弃所有插入的数据，不做任何保存 。 但服务器会记录Blackhole表的日志，所以可以用于复制数据到备库，或者简单地记录到日志。但 这种应用方式会碰到很多问题，因此并不推荐。</p><ol start="5"><li>CSV引擎</li></ol><p>CSV引擎可以将普通的CSV文件作为MySQL的表来处理，但不支持索引 。</p><p>CSV引擎可以作为一种数据交换的机制，非常有用。</p><p>CSV存储的数据直接可以在操作系统里，用文本编辑器，或者excel读取。</p><ol start="6"><li>Memory引擎</li></ol><p>如果需要快速地访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么使用</p><p>Memory表是非常有用。</p><p>Memory表至少比MyISAM表要快一个数量级。</p><ol start="10"><li>视图与 临时表的区别</li></ol><p>视图和临时表是两种不同的数据库对象，它们在使用场景、创建方式、数据存储和生命周期等方面有显著区别。以下是它们的主要区别：</p><h3 id="_1-数据存储" tabindex="-1"><a class="header-anchor" href="#_1-数据存储"><span>1. 数据存储</span></a></h3><ul><li><p><strong>视图</strong>：</p><ul><li>视图是一个虚拟表，不实际存储数据。它依赖于基础表，数据通过查询基础表实时生成。</li><li>每次查询视图时，系统都会重新执行视图的定义查询，从基础表中获取数据。</li></ul></li><li><p><strong>临时表</strong>：</p><ul><li>临时表是一种实际存在的表，它会在创建时存储数据。</li><li>临时表的数据是独立的，临时表一旦创建后，数据可以被多次查询，直到临时表被删除或会话结束。</li></ul></li></ul><h3 id="_2-生命周期" tabindex="-1"><a class="header-anchor" href="#_2-生命周期"><span>2. 生命周期</span></a></h3><ul><li><p><strong>视图</strong>：</p><ul><li>视图是持久的，创建后一直存在，除非被显式删除（<code>DROP VIEW</code>）。</li><li>视图的生命周期与数据库实例相关，视图可以被多个用户和会话访问。</li></ul></li><li><p><strong>临时表</strong>：</p><ul><li>临时表的生命周期与数据库会话或事务相关。它可以是会话级临时表或事务级临时表： <ul><li>会话级：在会话关闭时自动删除。</li><li>事务级：事务结束时自动删除。</li></ul></li><li>临时表在每个会话中是独立的，其他会话看不到该临时表。</li></ul></li></ul><h3 id="_3-数据更新" tabindex="-1"><a class="header-anchor" href="#_3-数据更新"><span>3. 数据更新</span></a></h3><ul><li><p><strong>视图</strong>：</p><ul><li>视图通常是只读的，尤其是当它们涉及多个表或复杂查询（如聚合函数、分组、连接等）。 有些简单视图可以进行 <code>INSERT</code>、<code>UPDATE</code> 或 <code>DELETE</code> 操作，但限制较多，且最终这些操作会作用于基础表。</li><li>视图不持有数据的物理副本，因此更新操作是间接地在基础表上进行的。</li></ul></li><li><p><strong>临时表</strong>：</p><ul><li>临时表是一个实际的表，可以像普通表一样进行 <code>INSERT</code>、<code>UPDATE</code> 和 <code>DELETE</code> 操作，数据在表中持久化到临时表被删除或会话结束。</li><li>可以在临时表中存储中间结果，便于复杂查询中的重复使用。</li></ul></li></ul><h3 id="_4-使用场景" tabindex="-1"><a class="header-anchor" href="#_4-使用场景"><span>4. 使用场景</span></a></h3><ul><li><p><strong>视图</strong>：</p><ul><li>简化复杂查询：将复杂查询封装为视图，便于重用和维护。</li><li>提供数据抽象层：隐藏基础表的复杂结构，只展示需要的列或行。</li><li>提升数据安全性：限制用户访问基础表的某些敏感数据。</li></ul></li><li><p><strong>临时表</strong>：</p><ul><li>存储中间结果：在复杂查询或操作中，临时表可以存储中间结果，避免重复计算。</li><li>临时数据操作：当需要在会话或事务内存储和处理临时数据时，可以使用临时表。</li><li>加速查询：通过将复杂查询的中间结果存储在临时表中，可以避免在每次查询时重复计算。</li></ul></li></ul><h3 id="_5-创建语法" tabindex="-1"><a class="header-anchor" href="#_5-创建语法"><span>5. 创建语法</span></a></h3><ul><li><p><strong>视图</strong>：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">VIEW</span> view_name <span class="token keyword">AS</span>
<span class="token keyword">SELECT</span> column1<span class="token punctuation">,</span> column2
<span class="token keyword">FROM</span> table_name
<span class="token keyword">WHERE</span> condition<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>临时表</strong>：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TEMPORARY</span> <span class="token keyword">TABLE</span> temp_table_name <span class="token punctuation">(</span>
    column1 datatype<span class="token punctuation">,</span>
    column2 datatype
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="_6-作用域" tabindex="-1"><a class="header-anchor" href="#_6-作用域"><span>6. 作用域</span></a></h3><ul><li><p><strong>视图</strong>：</p><ul><li>作用于整个数据库，可以被任何有权限的用户访问和使用，视图本身的生命周期不限于当前会话。</li></ul></li><li><p><strong>临时表</strong>：</p><ul><li>作用域仅限于当前会话或事务，其他会话无法访问临时表。每个会话的临时表是独立的。</li></ul></li></ul><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><table><thead><tr><th>特性</th><th>视图</th><th>临时表</th></tr></thead><tbody><tr><td>数据存储</td><td>不存储数据，依赖基础表</td><td>存储数据，存储实际的查询结果</td></tr><tr><td>生命周期</td><td>持久存在，直到显式删除</td><td>会话或事务结束时自动删除</td></tr><tr><td>更新数据</td><td>可能是只读，有时可以更新基础表</td><td>可以自由更新数据，和普通表一样操作</td></tr><tr><td>使用场景</td><td>简化复杂查询，数据抽象和安全控制</td><td>存储临时数据，减少重复计算，提升性能</td></tr><tr><td>作用域</td><td>数据库级别，多个用户会话共享</td><td>当前会话或事务级别</td></tr></tbody></table><p>总的来说，视图适合用于简化查询和数据抽象，而临时表更适合用于存储临时数据或中间结果。</p><ol start="11"><li>什么是数据库事务？</li></ol><p>是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作； 这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行； 事务是一组不可再分割的操作集合（工作逻辑单元）</p><ol start="12"><li>事务的ACID特性是什么？ 原子性,一致性, 隔离性, 持久性 隔离性：并发事务互相干扰 （一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并 发执行的各个事务之间不能互相干扰）</li></ol><p>持久性：一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的</p><ol start="13"><li>并发事务会有哪些问题？</li></ol><p>多个事务并发执行一定会产生相互争夺资源的问题</p><p>脏读（Dirty read）</p><p>是一个事务在处理过程中读取了另外一个事务未提交的数据 当一个事务正在访问数据并且对其进行了修改，但是还没提交事务，这时另外一个事务也访问了这个数 据，然后使用了这个数据，因为这个数据的修改还没提交到数据库，所以另外一个事务读取的数据就是</p><p>“脏数据”，这种行为就是“脏读”，依据“脏数据”所做的操作可能是会出现问题的。</p><p>修改丢失（Lost of modify）</p><p>是指一个事务读取一个数据时，另外一个数据也访问了该数据，那么在第一个事务修改了这个数据之 后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，这种情况就被称为*修改丢 失</p><p>不可重复读（Unrepeatableread）</p><p><em>指在一个事务内多次读取同一数据，在这个事务还没结束时，另外一个事务也访问了这个数据并对这个 数据进行了修改，那么就可能造成第一个事务两次读取的数据不一致，这种情况就被称为</em>不可重复读。</p><p>幻读（Phantom read）</p><p>是指同一个事务内多次查询返回的结果集总数不一样（比如增加了或者减少了行记录）。幻读与不可重复读类似，幻读是指一个事务读取了几行数据，这个事务还没结束，接着另外一个事务插 入了一些数据，在随后的查询中，第一个事务读取到的数据就会比原本读取到的多，就好像发生了幻觉 一样，所以称为<strong>幻读</strong>。</p><ol start="14"><li>不可重复读和幻读有什么区别？</li></ol><p>不可重复读 针对的是一份数据的修改 幻读 针对的是行数修改</p><ol start="15"><li>什么是事务隔离级别？ MySQL InnoDB 存储引擎默认的事务隔离级别是可重复读（REPEATABLE-READ）</li></ol><p>事务隔离级别 脏读 不可重复读(被修改) 幻读（删减） 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否</p><ol start="16"><li>Mysql事务隔离是如何实现的？</li></ol><p>隔离的实现主要是读写锁和MVCC</p><ol start="17"><li>表级锁和行级锁有什么区别？</li></ol><p>表级锁：串行化（serializable）时，整表加锁，事务访问表数据时需要申请锁，虽然可分为读锁和写 锁，但毕竟是锁住整张表，会导致并发能力下降，一般是做ddl处理时使用 行级锁：除了串行化（serializable）时 InnoDB使用的都是行级锁，只锁一行数据，其他行数据不影 响，并发能力强。</p><ol start="18"><li>什么是行级锁？Mysql如何完成的？</li></ol><p>行级锁实现比较复杂不是单纯锁住一行数据，是由mvcc完成的。</p><ol start="19"><li>什么是共享锁（读锁）？</li></ol><p>共享锁或S锁，其它事务可以继续加共享锁，但不能加排它锁</p><ol start="20"><li>什么是排它锁（写锁/独占锁）？</li></ol><p>排它锁或X锁，在进行写操作之前要申请并获得，其它事务不能再获得任何锁。</p><ol start="21"><li>mysql 读锁和写锁的实现</li></ol><p>在 MySQL 中，读锁和写锁是为了确保数据一致性和并发性而实现的。以下是对这两种锁的实现和工作原理的详细说明：</p><h3 id="_1-读锁-shared-lock" tabindex="-1"><a class="header-anchor" href="#_1-读锁-shared-lock"><span>1. <strong>读锁（Shared Lock）</strong></span></a></h3><ul><li><p><strong>概念</strong>：读锁允许多个事务并发读取同一数据行，但不允许其他事务对其进行写操作。多个事务可以同时持有读锁，但一旦有事务持有读锁，其他事务不能获得写锁。</p></li><li><p><strong>实现</strong>：</p><ul><li><strong>加锁机制</strong>：当一个事务请求对某个行加读锁时，MySQL 会检查当前是否有写锁。如果没有写锁存在，事务就可以成功获得读锁。</li><li><strong>行级锁</strong>：在 InnoDB 存储引擎中，读锁是行级锁。它仅锁定当前查询涉及的行，而不是整个表。这种方式允许更高的并发性。</li></ul></li><li><p><strong>使用</strong>：</p><ul><li>使用 <code>SELECT ... LOCK IN SHARE MODE</code> 或 <code>SELECT ... FOR UPDATE</code> 来显式地请求读锁。</li></ul></li></ul><h3 id="_2-写锁-exclusive-lock" tabindex="-1"><a class="header-anchor" href="#_2-写锁-exclusive-lock"><span>2. <strong>写锁（Exclusive Lock）</strong></span></a></h3><ul><li><p><strong>概念</strong>：写锁不允许其他事务对同一数据行进行读或写操作。只有获得写锁的事务可以修改数据行。一旦事务获得写锁，其他事务将无法获取任何类型的锁，直到写锁被释放。</p></li><li><p><strong>实现</strong>：</p><ul><li><strong>加锁机制</strong>：当一个事务请求对某个行加写锁时，MySQL 会检查当前是否有读锁或写锁。如果有任何其他事务持有锁，该事务会被阻塞，直到所有锁被释放。</li><li><strong>行级锁</strong>：同样，在 InnoDB 存储引擎中，写锁也是行级锁，只锁定当前正在修改的行，保持了较高的并发性。</li></ul></li><li><p><strong>使用</strong>：</p><ul><li>使用 <code>SELECT ... FOR UPDATE</code> 来显式请求写锁。此语句会在选择行时同时加上写锁。</li></ul></li></ul><h3 id="_3-锁的粒度" tabindex="-1"><a class="header-anchor" href="#_3-锁的粒度"><span>3. <strong>锁的粒度</strong></span></a></h3><ul><li><strong>表级锁 vs 行级锁</strong>：虽然上面提到的锁是行级锁，MySQL 也支持表级锁，但表级锁的并发性能较差。表级锁会锁定整个表，因此在高并发情况下，性能会受到影响。</li></ul><h3 id="_4-锁的行为" tabindex="-1"><a class="header-anchor" href="#_4-锁的行为"><span>4. <strong>锁的行为</strong></span></a></h3><ul><li><p><strong>死锁</strong>：在多个事务同时请求锁的情况下，可能会导致死锁。在这种情况下，MySQL 会自动检测死锁并回滚其中一个事务以释放锁。</p></li><li><p><strong>锁等待</strong>：当事务请求的锁被其他事务占用时，该事务会进入等待状态，直到锁被释放。</p></li></ul><h3 id="_5-使用场景" tabindex="-1"><a class="header-anchor" href="#_5-使用场景"><span>5. <strong>使用场景</strong></span></a></h3><ul><li><p><strong>读锁的使用场景</strong>：</p><ul><li>在数据读取的操作中，可以使用读锁来确保读取的数据在其他事务进行写操作时不会变化。</li></ul></li><li><p><strong>写锁的使用场景</strong>：</p><ul><li>在数据更新或删除时，需要使用写锁，以确保对数据的修改是安全的，不会被其他并发事务影响。</li></ul></li></ul><h3 id="_6-示例" tabindex="-1"><a class="header-anchor" href="#_6-示例"><span>6. <strong>示例</strong></span></a></h3><ul><li><p><strong>读锁示例</strong>：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">START</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> your_table <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">LOCK</span> <span class="token operator">IN</span> <span class="token keyword">SHARE</span> <span class="token keyword">MODE</span><span class="token punctuation">;</span>
<span class="token comment">-- 进行读取操作</span>
<span class="token keyword">COMMIT</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>写锁示例</strong>：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">START</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> your_table <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span> <span class="token keyword">FOR</span> <span class="token keyword">UPDATE</span><span class="token punctuation">;</span>
<span class="token comment">-- 进行写入操作</span>
<span class="token keyword">UPDATE</span> your_table <span class="token keyword">SET</span> <span class="token keyword">column</span> <span class="token operator">=</span> <span class="token keyword">value</span> <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token keyword">COMMIT</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><ol start="22"><li>Mysql会产生几种日志</li></ol><p>错误日志（error log）</p><p>error log主要记录MySQL在启动、关闭或者运行过程中的错误信息，在MySQL的配置文件my.cnf中， 可以通过log-error=/var/log/mysqld.log 执行mysql错误日志的位置。</p><p>慢查询日志（slow query log）</p><p>MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语 句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。 long_query_time的默认值为10，意思是运行10秒以上的语句。 由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL， 希望能收集超过5秒的sql，结合之前explain进行全面分析。</p><p>默认情况下，MySQL数据库没有开启慢查询日志，需要我们手动来设置这个参数。</p><p>当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的 性能影响。慢查询日志支持将日志记录写入文件。</p><p>在生产环境中，如果要手工分析日志，查找、分析SQL，显然是个体力活，MySQL提供了日志分析工具</p><p>mysqldumpslow。</p><p>一般查询日志（general log）</p><p>general log 记录了客户端连接信息以及执行的SQL语句信息，通过MySQL的命令</p><p>重写日志（redo log） 回滚日志（undo log） 二进制日志（bin log</p><h3 id="总结-1" tabindex="-1"><a class="header-anchor" href="#总结-1"><span>总结</span></a></h3><p>MySQL 的读锁和写锁通过行级锁的方式来控制并发事务的安全性。读锁允许多个事务同时读取，而写锁则确保数据的独占修改。通过合理使用这些锁，可以有效管理数据的并发访问和一致性。</p><h4 id="实战部分" tabindex="-1"><a class="header-anchor" href="#实战部分"><span>实战部分</span></a></h4><ol><li><p>列举几种表连接方式,有什么区别？</p><ol><li>内连接 (INNER JOIN): 内连接返回两个表中满足连接条件的所有记录。只有当连接键在两个表中都存在时，才会显示对应的结果行。</li><li>左连接 (LEFT JOIN / LEFT OUTER JOIN): 左连接以左表为基础，返回左表中的所有记录，即使右表中没有匹配的记录。如果右表中没有匹配项，则结果集中右表的部分将包含NULL值。</li><li>右连接 (RIGHT JOIN / RIGHT OUTER JOIN): 右连接与左连接相反，它以右表为基础，返回右表中的所有记录，左表中没有匹配的记录将以NULL值填充。</li><li>全外连接 (FULL OUTER JOIN): 全外连接返回左表和右表中的所有记录。如果某一边没有匹配项，则另一边相应的列值为NULL。</li><li>交叉连接 (CROSS JOIN): 交叉连接，也称为笛卡尔积，返回左表的每一行与右表的每一行的组合。如果没有指定ON条件，那么结果集的大小将是两个表行数的乘积。 区别: •数据覆盖范围: 内连接只显示匹配的记录，而左连接、右连接分别确保左表或右表的记录不丢失，全外连接则展示两边的所有记录，即使某些记录在另一侧没有匹配。 •NULL处理: 左连接和右连接会在缺少匹配时用NULL填充，全外连接可能在任一表缺少匹配时填充NULL。 •记录数量: 交叉连接会产生非常大的结果集，特别是当两个表都很庞大时。 这些连接类型的选择取决于你希望如何合并表中的数据以及你需要展现的信息详细程度</li></ol></li><li><p>mysql不支持full join？</p><p>是的，MySQL传统上并不直接支持FULL OUTER JOIN。 FULL OUTER JOIN会返回左表和右表中的所有行，匹配的行彼此相邻，而未匹配的行会在对应的另一侧填充NULL值。 尽管MySQL没有内置的FULL OUTER JOIN语法，但你可以通过使用UNION或者子查询来模拟这一行为，以联合LEFT JOIN和RIGHT JOIN的结果来达到相同的目的。</p><p>例如，要实现类似FULL OUTER JOIN的效果，可以这样做：</p><p>(SELECT a.<em>, b.</em> FROM table_a AS a LEFT JOIN table_b AS b ON a.id = b.id) UNION (SELECT a.<em>, b.</em> FROM table_a AS a RIGHT JOIN table_b AS b ON a.id = b.id)</p><ol><li><p>主键和外键的区别？</p><p>1.主键 (Primary Key): • 唯一性: 主键是用来唯一标识表中每一行记录的字段，确保不会有两行记录有相同的主键值。 • 非空性: 主键列不允许有NULL值。 • 索引: 通常情况下，主键自动创建唯一索引，这有助于快速查找和排序数据。 • 表约束: 每个表只能有一个主键，但主键可以由一个或多个列组成（复合主键）。</p><p>2.外键 (Foreign Key): • 引用完整性: 外键用于建立两个表之间的关联关系，它引用另一个表的主键。外键所在的表称为从表或子表，被引用的表称为父表或主表。 • 可为空性: 外键列可以包含NULL值，这意味着子表中的记录不必都与父表中的记录相对应。 • 维护引用关系: 外键约束可以帮助维护数据库的引用完整性，确保不能在子表中插入不存在于父表中的外键值，同时，在删除或更新父表中的记录时， 可以配置级联操作来同步更新或删除子表中的相关记录。 • 多对一或多对多关系: 外键是实现数据库中多对一或一对多关系的关键，通过它可以实现实体之间的关联查询。</p><p>如何创建呢？ CREATE TABLE employees ( employee_id INT NOT NULL, first_name VARCHAR(50), last_name VARCHAR(50), -- 其他列... PRIMARY KEY (employee_id) );</p><p>CREATE TABLE employees ( employee_id INT PRIMARY KEY, first_name VARCHAR(50), last_name VARCHAR(50), department_id INT, -- 其他列... FOREIGN KEY (department_id) REFERENCES departments(department_id) );</p></li></ol></li><li><p>order by与group by的区别</p><p>1.ORDER BY: 目的: 用于对查询结果进行排序，可以按照一个或多个列进行升序(ASC)或降序(DESC)排列。 位置: 通常放在 SQL 语句的末尾，但在使用聚合函数和 GROUP BY 时，可能位于 GROUP BY 之后。 应用场景: 当你需要按照特定列的值对结果集进行排序，以便于查看或分析数据时使用。</p><p>2.GROUP BY: 目的: 用于将查询结果集按照一个或多个列进行分组，每个组中包含具有相同列值的行。常与聚合函数如 SUM, AVG, COUNT, MAX, MIN 等一起使用，以计算每个组的汇总信息。 位置: 放在 WHERE子句之后，HAVING 子句之前（如果有的话）。 应用场景: 当需要对数据进行分类汇总统计时使用，例如计算每个部门的平均工资、每个类别的总销售额等。</p><p>总结来说，ORDER BY 关注的是查询结果的排序，而 GROUP BY 则关注于将数据分组并进行聚合计算。 两者可以结合使用，但要注意 GROUP BY 必须在 ORDER BY 之前（如果同时使用的话）</p></li><li><p>某个表有数千万数据，查询比较慢，如何优化？说一下思路</p></li></ol><p>在面对数千万条数据的表时，优化查询性能是一个重要的任务。以下是一些优化查询的思路和方法：</p><h3 id="_1-索引优化" tabindex="-1"><a class="header-anchor" href="#_1-索引优化"><span>1. <strong>索引优化</strong></span></a></h3><ul><li><strong>创建适当的索引</strong>：确保常用查询的字段上有索引，特别是用于过滤（<code>WHERE</code>）、排序（<code>ORDER BY</code>）和连接（<code>JOIN</code>）的字段。</li><li><strong>复合索引</strong>：考虑创建复合索引，涵盖多个列的查询条件，以减少查询时的扫描量。</li><li><strong>避免过度索引</strong>：虽然索引可以加快查询，但过多的索引会影响写入性能并占用存储空间，因此需要找到一个平衡点。</li></ul><h3 id="_2-查询优化" tabindex="-1"><a class="header-anchor" href="#_2-查询优化"><span>2. <strong>查询优化</strong></span></a></h3><ul><li><strong>使用合适的查询方式</strong>：尽量使用 <code>SELECT</code> 只获取需要的列，避免使用 <code>SELECT *</code>。</li><li><strong>减少子查询</strong>：考虑使用连接（<code>JOIN</code>）替代子查询，避免不必要的嵌套查询。</li><li><strong>过滤数据</strong>：尽量在查询中使用 <code>WHERE</code> 条件过滤数据，减少结果集大小。</li><li><strong>分页查询</strong>：对于大数据集的查询，使用分页（如 <code>LIMIT</code> 和 <code>OFFSET</code>）来分批处理数据。</li></ul><h3 id="_4-数据库配置" tabindex="-1"><a class="header-anchor" href="#_4-数据库配置"><span>4. <strong>数据库配置</strong></span></a></h3><ul><li><strong>调整数据库参数</strong>：根据应用需求和服务器配置，优化数据库的参数，如缓冲区大小、缓存设置等，以提升性能。</li><li><strong>使用连接池</strong>：在应用层面使用数据库连接池，减少频繁创建和关闭数据库连接的开销。</li></ul><h3 id="_5-查询分析" tabindex="-1"><a class="header-anchor" href="#_5-查询分析"><span>5. <strong>查询分析</strong></span></a></h3><ul><li><strong>使用 <code>EXPLAIN</code></strong>：利用 <code>EXPLAIN</code> 语句分析查询的执行计划，找出性能瓶颈。</li><li><strong>分析慢查询</strong>：启用慢查询日志，记录执行时间超过特定阈值的查询，针对这些查询进行优化。</li></ul><h3 id="_6-分区表" tabindex="-1"><a class="header-anchor" href="#_6-分区表"><span>6. <strong>分区表</strong></span></a></h3><ul><li><strong>表分区</strong>：对于非常大的表，可以考虑使用分区（Partitioning）来将表分为更小的、独立的部分，这样可以加速某些查询。</li></ul><h3 id="_7-缓存机制" tabindex="-1"><a class="header-anchor" href="#_7-缓存机制"><span>7. <strong>缓存机制</strong></span></a></h3><ul><li><strong>应用层缓存</strong>：使用缓存机制（如 Redis、Memcached）缓存常用查询结果，减少对数据库的直接查询。</li><li><strong>数据库缓存</strong>：确保数据库本身的查询缓存功能开启，并适当配置。</li></ul><h3 id="_8-硬件优化" tabindex="-1"><a class="header-anchor" href="#_8-硬件优化"><span>8. <strong>硬件优化</strong></span></a></h3><ul><li><strong>升级硬件</strong>：如果上述优化措施仍未能满足性能需求，考虑增加硬件资源，如增加内存、使用更快的硬盘（如 SSD）等。</li></ul><h3 id="总结-2" tabindex="-1"><a class="header-anchor" href="#总结-2"><span>总结</span></a></h3><p>优化数据库查询性能通常需要综合考虑多种因素，进行逐步分析和调整。通过索引优化、查询优化、表结构优化、数据库配置、使用缓存和硬件升级等手段，能够有效提高查询性能。 重要的是定期分析查询性能和执行计划，以便不断优化。</p><ol start="5"><li>count(列名)和 count(*)有什么区别？</li></ol><p>count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。</p><ol start="6"><li>如何优化过多join查询关联？</li></ol><p>适当使用冗余字段减少多表关联查询 驱动表和被驱动表（小表join大表） 业务允许的话 尽量使用inner join 让系统帮忙自动选择驱动表 关联字段一定创建索引 调整JOIN BUFFER大小</p><h4 id="mysql分库分表" tabindex="-1"><a class="header-anchor" href="#mysql分库分表"><span>MySQL分库分表</span></a></h4><ol><li><p>什么情况下需要分库？什么情况下需要分表？</p><p>当数据库的QPS过高，数据库连接数不足的时候，就需要分库。 当单表数据量过大，读写性能较差，就需要分表。 当两者都有的时候，就需要分库分表。</p><p>至于先分库还是先分表？建议先分表，如果分表能解决问题，就不需要分库了，毕竟需要单独服务器资源，成本更高</p></li><li><p>如何实现分库分表？有哪些拆分方式？</p></li></ol><p>分库分表有垂直拆分和水平拆分。垂直拆分又有垂直分库、垂直分表。</p><p>垂直分库，不同的业务拆分到不同的数据库。</p><p>垂直分表，把长度较大或者访问频次较低的字段，拆分到扩展表中。</p><p>水平分表，单表数据量过大时，按照订单ID拆分到多张表中。</p><ol start="3"><li>分库分表引入哪些问题？</li></ol><p>垂直分库： 不同库多表之间无法join关联查询，只能通过接口聚合，复杂度直线上升。 横跨多个数据库导致无法使用本地事务，数据强一致性就别想了，只能引入更为复杂的分布式事务，勉强实现数据的最终一致性，可用性直线下降。</p><p>垂直分表： 本来一张表能查出来的数据，现在需要多张表join关联查询，这不瞎耽误事。</p><p>水平分表： 多张表关联查询时，无法实现分页、排序功能。</p><ol start="4"><li>分库分表引入问题的解决方案？</li></ol><p>跨库查询问题： 采用字段冗余方案，比如订单表存储店铺ID、店铺名称，就不需要再查询商户数据库了。 不过这种方案要求冗余字段要很少变动，就算变动后，也能容忍返回旧数据。 多表分页查询问题： 这个处理起来就很需要技术含量了。 比如：订单表按照订单ID分片，(order_id % 128)，分成了128张表。 Leader看了说：每张表的数据量差不多，分的很均匀，以后不要再分了。 同一个用户的订单散落在不同的表，用户想查询自己的订单，根本无法做到分页查询。难道一次全部查询该用户的所有订单，然后做内存分页，多大的机器内存都让你搞挂。 想要实现用户订单分页查询，可以采用按照用户ID分片，(user_id % 128)，这样同一个用户的订单只会存储在一张表中，咋分页展示都行。 没有完美的分片方案，如果商户想要分页查看自己店铺的订单怎么办？ 那就把订单再冗余存储一份，按照店铺ID分片，(shop_id % 128)。不过由于商户数量较少，可以搞个异步线程往商户订单分片表同步。 订单按照用户ID分片后，发生数据倾斜怎么办？ 因为不同用户的订单量是不同的，一个爱好购物的小姐姐的订单量抵得上几十个老爷们。导致一张表数据几百条，另一张表数据量千万级，这该咋整？ 做冷热数据分离，基础库只存储3个月内的订单，其他的移动到历史订单库。这个要跟产品商量好，3个月前的订单需要单独的查询页面。</p><h2 id="redis" tabindex="-1"><a class="header-anchor" href="#redis"><span>REDIS</span></a></h2>`,135),g=i('<ul><li><a href="#1%E4%BB%80%E4%B9%88%E6%98%AFredisredis%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E7%82%B9">1、什么是Redis，Redis有哪些特点？</a></li><li><a href="#2redis%E6%9C%89%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">2、Redis有哪些数据结构？</a></li><li><a href="#3%E4%B8%80%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%80%BC%E8%83%BD%E5%AD%98%E5%82%A8%E6%9C%80%E5%A4%A7%E5%AE%B9%E9%87%8F%E6%98%AF%E5%A4%9A%E5%B0%91">3、一个字符串类型的值能存储最大容量是多少？</a></li><li><a href="#4%E8%83%BD%E8%AF%B4%E4%B8%80%E4%B8%8Bredis%E6%AF%8F%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%90%97">4、能说一下Redis每种数据结构的使用场景吗？</a></li><li><a href="#5redis%E5%A6%82%E4%BD%95%E5%81%9A%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E8%83%BD%E8%AF%B4%E4%B8%80%E4%B8%8Brdb%E5%92%8Caof%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%90%97">5、Redis如何做持久化的？能说一下RDB和AOF的实现原理吗？</a><ul><li><a href="#rdb%E6%8C%81%E4%B9%85%E5%8C%96">RDB持久化</a></li><li><a href="#aof%E6%8C%81%E4%B9%85%E5%8C%96">AOF持久化</a></li><li><a href="#rdb%E5%92%8Caof%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9">RDB和AOF的优缺点</a></li></ul></li><li><a href="#6%E8%AE%B2%E8%A7%A3%E4%B8%80%E4%B8%8Bredis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B">6、讲解一下Redis的线程模型？</a></li><li><a href="#7%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%BC%93%E5%AD%98%E9%99%8D%E7%BA%A7%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88">7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么？</a><ul><li><a href="#1%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F">（1）缓存穿透</a></li><li><a href="#2%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF">（2）缓存击穿</a></li><li><a href="#3%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9">（3）缓存雪崩</a></li><li><a href="#4%E7%BC%93%E5%AD%98%E9%A2%84%E7%83%AD">（4）缓存预热</a></li><li><a href="#5%E7%BC%93%E5%AD%98%E9%99%8D%E7%BA%A7">（5）缓存降级</a></li></ul></li><li><a href="#8redis%E7%9A%84%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6">8、Redis的内存淘汰机制</a></li><li><a href="#9redis%E6%9C%89%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%E5%90%97">9、Redis有事务机制吗？</a></li><li><a href="#10redis%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E5%8E%9F%E5%AD%90%E6%80%A7%E7%9A%84">10、Redis事务到底是不是原子性的？</a></li><li><a href="#11redis%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%94%AF%E6%8C%81%E5%9B%9E%E6%BB%9Aroll-back">11、Redis为什么不支持回滚（roll back）？</a></li><li><a href="#12redis%E4%BA%8B%E5%8A%A1%E7%9B%B8%E5%85%B3%E7%9A%84%E5%91%BD%E4%BB%A4%E6%9C%89%E5%93%AA%E5%87%A0%E4%B8%AA">12、Redis事务相关的命令有哪几个？</a></li><li><a href="#13%E4%BB%80%E4%B9%88%E6%98%AFredis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6">13、什么是Redis主从复制？</a></li><li><a href="#14sentinel%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8E%9F%E7%90%86%E4%BD%A0%E8%83%BD%E8%AE%B2%E4%B8%80%E4%B8%8B%E5%90%97">14、Sentinel（哨兵模式）的原理你能讲一下吗？</a></li><li><a href="#15cluster%E9%9B%86%E7%BE%A4%E7%9A%84%E5%8E%9F%E7%90%86%E4%BD%A0%E8%83%BD%E8%AE%B2%E4%B8%80%E4%B8%8B%E5%90%97">15、Cluster（集群）的原理你能讲一下吗？</a></li><li><a href="#16memcache%E4%B8%8Eredis%E7%9A%84%E5%8C%BA%E5%88%AB%E9%83%BD%E6%9C%89%E5%93%AA%E4%BA%9B">16、Memcache与Redis的区别都有哪些？</a></li><li><a href="#17%E5%81%87%E5%A6%82redis%E9%87%8C%E9%9D%A2%E6%9C%891%E4%BA%BF%E4%B8%AAkey%E5%85%B6%E4%B8%AD%E6%9C%8910w%E4%B8%AAkey%E6%98%AF%E4%BB%A5%E6%9F%90%E4%B8%AA%E5%9B%BA%E5%AE%9A%E7%9A%84%E5%B7%B2%E7%9F%A5%E7%9A%84%E5%89%8D%E7%BC%80%E5%BC%80%E5%A4%B4%E7%9A%84%E5%A6%82%E6%9E%9C%E5%B0%86%E5%AE%83%E4%BB%AC%E5%85%A8%E9%83%A8%E6%89%BE%E5%87%BA%E6%9D%A5">17、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</a></li><li><a href="#18%E5%A6%82%E6%9E%9C%E8%BF%99%E4%B8%AAredis%E6%AD%A3%E5%9C%A8%E7%BB%99%E7%BA%BF%E4%B8%8A%E7%9A%84%E4%B8%9A%E5%8A%A1%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E9%82%A3%E4%BD%BF%E7%94%A8keys%E6%8C%87%E4%BB%A4%E4%BC%9A%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98">18、如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</a></li><li><a href="#19%E5%A6%82%E6%9E%9C%E6%9C%89%E5%A4%A7%E9%87%8F%E7%9A%84key%E9%9C%80%E8%A6%81%E8%AE%BE%E7%BD%AE%E5%90%8C%E4%B8%80%E6%97%B6%E9%97%B4%E8%BF%87%E6%9C%9F%E4%B8%80%E8%88%AC%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E4%BB%80%E4%B9%88">19、如果有大量的key需要设置同一时间过期，一般需要注意什么？</a></li><li><a href="#20redis%E5%B8%B8%E7%94%A8%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9C%89%E5%93%AA%E4%BA%9B">20、Redis常用的客户端有哪些？</a></li></ul>',1),h=i(`<h1 id="_1、什么是redis-redis有哪些特点" tabindex="-1"><a class="header-anchor" href="#_1、什么是redis-redis有哪些特点"><span>1、什么是Redis，Redis有哪些特点？</span></a></h1><p>Redis全称为：Remote Dictionary Server（远程数据服务），Redis是一种支持key-value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。</p><p><strong>特点1：丰富的数据类型</strong></p><p>我们知道很多数据库只能处理一种数据结构：</p><ul><li>传统SQL数据库处理二维关系数据；</li><li>MemCached数据库，键和值都是字符串；</li><li>文档数据库（MongoDB）是由Json/Bson组成的文档。</li></ul><p>当然不是他们这些数据库不好，而是一旦数据库提供数据结构不适合去做某件事情的话，程序写起来就非常麻烦和不自然。</p><p>Redis虽然也是键值对数据库，但是和Memcached不同的是：Redis的值不仅可以是字符串，它还可以是其他五中数据机构中的任意一种。通过选用不同的数据结构，用户可以使用Redis解决各种各样的问题，使用Redis，你碰到一个问题，首先会想到是选用那种数据结构把哪些功能问题解决掉，有了多样的数据结构，方便你解决问题。</p><p><strong>特点2：内存存储</strong></p><p>数据库有两种：一种是硬盘数据库，一种是内存数据库。</p><p>硬盘数据库是把值存储在硬盘上，在内存中就存储一下索引，当硬盘数据库想访问硬盘的值时，它先在内存里找到索引，然后再找值。问题在于，在读取和写入硬盘的时候，如果读写比较多的时候，它会把硬盘的IO功能堵死。</p><p>内存存储是讲所有的数据都存储在内存里面，数据读取和写入速度非常快。</p><p><strong>特点3：持久化功能</strong></p><p>将数据存储在内存里面的数据保存到硬盘中，保证数据安全，方便进行数据备份和恢复。</p><h1 id="_2、redis有哪些数据结构" tabindex="-1"><a class="header-anchor" href="#_2、redis有哪些数据结构"><span>2、Redis有哪些数据结构？</span></a></h1><p>Redis是key-value数据库，key的类型只能是String，但是value的数据类型就比较丰富了，主要包括五种：</p><ul><li>String</li><li>Hash</li><li>List</li><li>Set</li><li>Sorted Set</li></ul><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222748.png" width="300"></div><br><p><strong>（1）String字符串</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>SET KEY_NAME VALUE
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。</p><p><strong>（2）Hash哈希</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>HSET KEY_NAME FIELD VALUE
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis hash 是一个键值(key=&gt;value)对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</p><p><strong>（3）List列表</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>//在 key 对应 list 的头部添加字符串元素
LPUSH KEY_NAME VALUE1.. VALUEN
//在 key 对应 list 的尾部添加字符串元素
RPUSH KEY_NAME VALUE1..VALUEN
//对应 list 中删除 count 个和 value 相同的元素
LREM KEY_NAME COUNT VALUE
//返回 key 对应 list 的长度
LLEN KEY_NAME 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Redis 列表是简单的字符串列表，按照插入顺序排序。 可以添加一个元素到列表的头部（左边）或者尾部（右边）</p><p><strong>（4）Set集合</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>SADD KEY_NAME VALUE1...VALUEn
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。</p><p><strong>（5）Sorted Set有序集合</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>ZADD KEY_NAME SCORE1 VALUE1.. SCOREN VALUEN
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。</p><p>redis正是通过分数来为集合中的成员进行从小到大的排序。</p><p>zset的成员是唯一的,但分数(score)却可以重复。</p><h1 id="_3、一个字符串类型的值能存储最大容量是多少" tabindex="-1"><a class="header-anchor" href="#_3、一个字符串类型的值能存储最大容量是多少"><span>3、一个字符串类型的值能存储最大容量是多少？</span></a></h1>`,41),u={href:"https://redis.io/topics/data-types",target:"_blank",rel:"noopener noreferrer"},A=i(`<div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222920.jpeg" width=""></div><br><h1 id="_4、能说一下redis每种数据结构的使用场景吗" tabindex="-1"><a class="header-anchor" href="#_4、能说一下redis每种数据结构的使用场景吗"><span>4、能说一下Redis每种数据结构的使用场景吗？</span></a></h1><p><strong>（1）String的使用场景</strong></p><p>字符串类型的使用场景：信息缓存、计数器、分布式锁等等。</p><p>常用命令：get/set/del/incr/decr/incrby/decrby</p><p><strong>实战场景1：记录每一个用户的访问次数，或者记录每一个商品的浏览次数</strong></p><p>方案：</p><p>常用键名： userid:pageview 或者 pageview:userid，如果一个用户的id为123，那对应的redis key就为pageview:123，value就为用户的访问次数，增加次数可以使用命令：incr。</p><p>使用理由：每一个用户访问次数或者商品浏览次数的修改是很频繁的，如果使用mysql这种文件系统频繁修改会造成mysql压力，效率也低。而使用redis的好处有二：使用内存，很快；单线程，所以无竞争，数据不会被改乱。</p><p><strong>实战场景2：缓存频繁读取，但是不常修改的信息，如用户信息，视频信息</strong></p><p>方案：</p><p>业务逻辑上：先从redis读取，有值就从redis读取，没有则从mysql读取，并写一份到redis中作为缓存，注意要设置过期时间。</p><p>键值设计上：</p><p>直接将用户一条mysql记录做序列化(通常序列化为json)作为值，userInfo:userid 作为key，键名如：userInfo:123，value存储对应用户信息的json串。如 key为：&quot;user:id :name:1&quot;, value为&quot;{&quot;name&quot;:&quot;leijia&quot;,&quot;age&quot;:18}&quot;。</p><p><strong>实战场景3：限定某个ip特定时间内的访问次数</strong></p><p>方案：</p><p>用key记录IP，value记录访问次数，同时key的过期时间设置为60秒，如果key过期了则重新设置，否则进行判断，当一分钟内访问超过100次，则禁止访问。</p><p><strong>实战场景4:分布式session</strong></p><p>我们知道session是以文件的形式保存在服务器中的；如果你的应用做了负载均衡，将网站的项目放在多个服务器上，当用户在服务器A上进行登陆，session文件会写在A服务器；当用户跳转页面时，请求被分配到B服务器上的时候，就找不到这个session文件，用户就要重新登陆。</p><p>如果想要多个服务器共享一个session，可以将session存放在redis中，redis可以独立于所有负载均衡服务器，也可以放在其中一台负载均衡服务器上；但是所有应用所在的服务器连接的都是同一个redis服务器。</p><p><strong>（2）Hash的使用场景</strong></p><p>以购物车为例子，用户id设置为key，那么购物车里所有的商品就是用户key对应的值了，每个商品有id和购买数量，对应hash的结构就是商品id为field，商品数量为value。如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223018.jpeg" width="200"></div><br><p>如果将商品id和商品数量序列化成json字符串，那么也可以用上面讲的string类型存储。下面对比一下这两种数据结构：</p><table><thead><tr><th style="text-align:left;">对比项</th><th style="text-align:left;">string（json）</th><th style="text-align:left;">hash</th></tr></thead><tbody><tr><td style="text-align:left;">效率</td><td style="text-align:left;">很高</td><td style="text-align:left;">高</td></tr><tr><td style="text-align:left;">容量</td><td style="text-align:left;">低</td><td style="text-align:left;">低</td></tr><tr><td style="text-align:left;">灵活性</td><td style="text-align:left;"><strong>低</strong></td><td style="text-align:left;">高</td></tr><tr><td style="text-align:left;">序列化</td><td style="text-align:left;">简单</td><td style="text-align:left;"><strong>复杂</strong></td></tr></tbody></table><p>总结一下：</p><p>当对象的某个属性需要频繁修改时，不适合用string+json，因为它不够灵活，每次修改都需要重新将整个对象序列化并赋值；如果使用hash类型，则可以针对某个属性单独修改，没有序列化，也不需要修改整个对象。比如，商品的价格、销量、关注数、评价数等可能经常发生变化的属性，就适合存储在hash类型里。</p><p><strong>（3）List的使用场景</strong></p><p>列表本质是一个有序的，元素可重复的队列。</p><p><strong>实战场景：定时排行榜</strong></p><p>list类型的lrange命令可以分页查看队列中的数据。可将每隔一段时间计算一次的排行榜存储在list类型中，如QQ音乐内地排行榜，每周计算一次存储再list类型中，访问接口时通过page和size分页转化成lrange命令获取排行榜数据。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223052.jpeg" width="200"></div><br><p>但是，并不是所有的排行榜都能用list类型实现，只有定时计算的排行榜才适合使用list类型存储，与定时计算的排行榜相对应的是实时计算的排行榜，list类型不能支持实时计算的排行榜，下面介绍有序集合sorted set的应用场景时会详细介绍实时计算的排行榜的实现。</p><p><strong>（4）Set的使用场景</strong></p><p>集合的特点是无序性和确定性（不重复）。</p><p><strong>实战场景：收藏夹</strong></p><p>例如QQ音乐中如果你喜欢一首歌，点个『喜欢』就会将歌曲放到个人收藏夹中，每一个用户做一个收藏的集合，每个收藏的集合存放用户收藏过的歌曲id。</p><p>key为用户id，value为歌曲id的集合。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223310.jpeg" width="200"></div><br><p><strong>（5）Sorted Set的使用场景</strong></p><p>有序集合的特点是有序，无重复值。与set不同的是sorted set每个元素都会关联一个score属性，redis正是通过score来为集合中的成员进行从小到大的排序。</p><p><strong>实战场景：实时排行榜</strong></p><p>QQ音乐中有多种实时榜单，比如飙升榜、热歌榜、新歌榜，可以用redis key存储榜单类型，score为点击量，value为歌曲id，用户每点击一首歌曲会更新redis数据，sorted set会依据score即点击量将歌曲id排序。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223348.jpeg" width="200"></div><br><h1 id="_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗" tabindex="-1"><a class="header-anchor" href="#_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗"><span>5、Redis如何做持久化的？能说一下RDB和AOF的实现原理吗？</span></a></h1><p><strong>什么是持久化？</strong></p><p>持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223421.png" width=""></div><br><p>还可以从如下两个层面简单的理解持久化 ：</p><ul><li>应用层：如果关闭(shutdown)你的应用然后重新启动则先前的数据依然存在。</li><li>系统层：如果关闭(shutdown)你的系统（电脑）然后重新启动则先前的数据依然存在。</li></ul><p><strong>Redis为什么要持久化？</strong></p><p>Redis是内存数据库，为了保证效率所有的操作都是在内存中完成。数据都是缓存在内存中，当你重启系统或者关闭系统，之前缓存在内存中的数据都会丢失再也不能找回。因此为了避免这种情况，Redis需要实现持久化将内存中的数据存储起来。</p><p><strong>Redis如何实现持久化？</strong></p><p>Redis官方提供了不同级别的持久化方式：</p><ul><li>RDB持久化：能够在指定的时间间隔能对你的数据进行快照存储。</li><li>AOF持久化：记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。</li><li>不使用持久化：如果你只希望你的数据在服务器运行的时候存在，你也可以选择不使用任何持久化方式。</li><li>同时开启RDB和AOF：你也可以同时开启两种持久化方式，在这种情况下当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</li></ul><p>这么多持久化方式我们应该怎么选？在选择之前我们需要搞清楚每种持久化方式的区别以及各自的优劣势。</p><h2 id="rdb持久化" tabindex="-1"><a class="header-anchor" href="#rdb持久化"><span>RDB持久化</span></a></h2><p>RDB(Redis Database)持久化是把当前内存数据生成快照保存到硬盘的过程，触发RDB持久化过程分为<strong>手动触发</strong>和<strong>自动触发</strong>。</p><p>（1）手动触发</p><p>手动触发对应save命令，会阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。</p><p>（2）自动触发</p><p>自动触发对应bgsave命令，Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</p><p>在redis.conf配置文件中可以配置：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>save &lt;seconds&gt; &lt;changes&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>表示xx秒内数据修改xx次时自动触发bgsave。 如果想关闭自动触发，可以在save命令后面加一个空串，即：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>save &quot;&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>还有其他常见可以触发bgsave，如：</p><ul><li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。</li><li>默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则 自动执行bgsave。</li></ul><p><strong>bgsave工作机制</strong></p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223529.png" width="300"></div><br><p>（1）执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进 程，如RDB/AOF子进程，如果存在，bgsave命令直接返回。</p><p>（2）父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞，通 过info stats命令查看latest_fork_usec选项，可以获取最近一个fork操作的耗时，单位为微秒</p><p>（3）父进程fork完成后，bgsave命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令。</p><p>（4）子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave命令可以获取最后一次生成RDB的 时间，对应info统计的rdb_last_save_time选项。</p><p>（5）进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence下的rdb_*相关选项。</p><p>-- RDB持久化完 --</p><h2 id="aof持久化" tabindex="-1"><a class="header-anchor" href="#aof持久化"><span>AOF持久化</span></a></h2><p>AOF（append only file）持久化：以独立日志的方式记录每次写命令， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。</p><p><strong>AOF持久化工作机制</strong></p><p>开启AOF功能需要配置：appendonly yes，默认不开启。</p><p>AOF文件名 通过appendfilename配置设置，默认文件名是appendonly.aof。保存路径同 RDB持久化方式一致，通过dir配置指定。</p><p>AOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写（rewrite）、重启加载 （load）。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223557.png" width="200"></div><br><p>（1）所有的写入命令会追加到aof_buf（缓冲区）中。</p><p>（2）AOF缓冲区根据对应的策略向硬盘做同步操作。</p><p>AOF为什么把命令追加到aof_buf中？Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。</p><p>（3）随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。</p><p>（4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。</p><p><strong>AOF重写（rewrite）机制</strong></p><p>重写的目的：</p><ul><li>减小AOF文件占用空间；</li><li>更小的AOF 文件可以更快地被Redis加载恢复。</li></ul><p>AOF重写可以分为手动触发和自动触发：</p><ul><li>手动触发：直接调用bgrewriteaof命令。</li><li>自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。</li></ul><p>auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认 为64MB。</p><p>auto-aof-rewrite-percentage：代表当前AOF文件空间 （aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比值。</p><p>自动触发时机</p><p>当aof_current_size&gt;auto-aof-rewrite-minsize 并且（aof_current_size-aof_base_size）/aof_base_size&gt;=auto-aof-rewritepercentage。</p><p>其中aof_current_size和aof_base_size可以在info Persistence统计信息中查看。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223632.png" width="300"></div><br><p>AOF文件重写后为什么会变小？</p><p>（1）旧的AOF文件含有无效的命令，如：del key1， hdel key2等。重写只保留最终数据的写入命令。</p><p>（2）多条命令可以合并，如lpush list a，lpush list b，lpush list c可以直接转化为lpush list a b c。</p><p><strong>AOF文件数据恢复</strong></p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223700.png" width="300"></div><br><p>数据恢复流程说明：</p><p>（1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。</p><p>（2）AOF关闭或者AOF文件不存在时，加载RDB文件。</p><p>（3）加载AOF/RDB文件成功后，Redis启动成功。</p><p>（4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。</p><p>-- AOF持久化完 --</p><h2 id="rdb和aof的优缺点" tabindex="-1"><a class="header-anchor" href="#rdb和aof的优缺点"><span>RDB和AOF的优缺点</span></a></h2><p><strong>RDB优点</strong></p><ul><li>RDB 是一个非常紧凑的文件,它保存了某个时间点的数据集,非常适用于数据集的备份,比如你可以在每个小时报保存一下过去24小时内的数据,同时每天保存过去30天的数据,这样即使出了问题你也可以根据需求恢复到不同版本的数据集。</li><li>RDB 是一个紧凑的单一文件,很方便传送到另一个远端数据中心，非常适用于灾难恢复。</li><li>RDB 在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以 RDB 持久化方式可以最大化 Redis 的性能。</li><li>与AOF相比,在恢复大的数据集的时候，RDB 方式会更快一些。</li></ul><p><strong>AOF优点</strong></p><ul><li>你可以使用不同的 fsync 策略：无 fsync、每秒 fsync 、每次写的时候 fsync .使用默认的每秒 fsync 策略, Redis 的性能依然很好( fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据。</li><li>AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题。</li><li>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li><li>AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li></ul><p><strong>RDB缺点</strong></p><ul><li>Redis 要完整的保存整个数据集是一个比较繁重的工作,你通常会每隔5分钟或者更久做一次完整的保存,万一在 Redis 意外宕机,你可能会丢失几分钟的数据。</li><li>RDB 需要经常 fork 子进程来保存数据集到硬盘上,当数据集比较大的时候, fork 的过程是非常耗时的,可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。</li></ul><p><strong>AOF缺点</strong></p><ul><li>对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。</li><li>数据恢复（load）时AOF比RDB慢，通常RDB 可以提供更有保证的最大延迟时间。</li></ul><p><strong>RDB和AOF简单对比总结</strong></p><p>RDB优点：</p><ul><li>RDB 是紧凑的二进制文件，比较适合备份，全量复制等场景</li><li>RDB 恢复数据远快于 AOF</li></ul><p>RDB缺点：</p><ul><li>RDB 无法实现实时或者秒级持久化；</li><li>新老版本无法兼容 RDB 格式。</li></ul><p>AOF优点：</p><ul><li>可以更好地保护数据不丢失；</li><li>appen-only 模式写入性能比较高；</li><li>适合做灾难性的误删除紧急恢复。</li></ul><p>AOF缺点：</p><ul><li>对于同一份文件，AOF 文件要比 RDB 快照大；</li><li>AOF 开启后，会对写的 QPS 有所影响，相对于 RDB 来说 写 QPS 要下降；</li><li>数据库恢复比较慢， 不合适做冷备。</li></ul><h1 id="_6、讲解一下redis的线程模型" tabindex="-1"><a class="header-anchor" href="#_6、讲解一下redis的线程模型"><span>6、讲解一下Redis的线程模型？</span></a></h1><p>redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。</p><p>如果面试官继续追问为啥 redis 单线程模型也能效率这么高？</p><ul><li>纯内存操作</li><li>核心是基于非阻塞的 IO 多路复用机制</li><li>单线程反而避免了多线程的频繁上下文切换问题</li></ul><h1 id="_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么" tabindex="-1"><a class="header-anchor" href="#_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么"><span>7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么？</span></a></h1><p>在实际生产环境中有时会遇到缓存穿透、缓存击穿、缓存雪崩等异常场景，为了避免异常带来巨大损失，我们需要了解每种异常发生的原因以及解决方案，帮助提升系统可靠性和高可用。</p><h2 id="_1-缓存穿透" tabindex="-1"><a class="header-anchor" href="#_1-缓存穿透"><span>（1）缓存穿透</span></a></h2><p><strong>什么是缓存穿透？</strong></p><p>缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。</p><p>如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统。</p><p><strong>缓存穿透常用的解决方案</strong></p><p><strong>（1）布隆过滤器（推荐）</strong></p><p>布隆过滤器（Bloom Filter，简称BF）由Burton Howard Bloom在1970年提出，是一种空间效率高的概率型数据结构。</p><p><strong>布隆过滤器专门用来检测集合中是否存在特定的元素。</strong></p><p>如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：</p><ul><li>采用线性表存储，查找时间复杂度为O(N)</li><li>采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为O(logN)</li><li>采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要O[log(n/m)]</li></ul><p>当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。接下来看一下布隆过滤器如何解决这个问题。</p><p><strong>布隆过滤器设计思想</strong></p><p>布隆过滤器由一个长度为m比特的位数组（bit array）与k个哈希函数（hash function）组成的数据结构。位数组初始化均为0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。</p><p>当要向布隆过滤器中插入一个元素时，该元素经过k个哈希函数计算产生k个哈希值，以哈希值作为位数组中的下标，将所有k个对应的比特值由0置为1。</p><p>当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后检查对应的k个比特值：如果有任意一个比特为0，表明该元素一定不在集合中；如果所有比特均为1，表明该集合有可能性在集合中。为什么不是一定在集合中呢？因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。</p><p>总结一下：布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。</p><p>举个例子：下图是一个布隆过滤器，共有18个比特位，3个哈希函数。集合中三个元素x，y，z通过三个哈希函数散列到不同的比特位，并将比特位置为1。当查询元素w时，通过三个哈希函数计算，发现有一个比特位的值为0，可以肯定认为该元素不在集合中。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223743.png" width="500"></div><br><p><strong>布隆过滤器优缺点</strong></p><p>优点：</p><ul><li>节省空间：不需要存储数据本身，只需要存储数据对应hash比特位</li><li>时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数</li></ul><p>缺点：</p><ul><li>存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数</li><li>不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了</li></ul><p><strong>布隆过滤器适用场景</strong></p><ul><li>爬虫系统url去重</li><li>垃圾邮件过滤</li><li>黑名单</li></ul><p><strong>（2）返回空对象</strong></p><p>当缓存未命中，查询持久层也为空，可以将返回的空对象写到缓存中，这样下次请求该key时直接从缓存中查询返回空对象，请求不会落到持久层数据库。为了避免存储过多空对象，通常会给空对象设置一个过期时间。</p><p>这种方法会存在两个问题：</p><ul><li>如果有大量的key穿透，缓存空对象会占用宝贵的内存空间。</li><li>空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。</li></ul><h2 id="_2-缓存击穿" tabindex="-1"><a class="header-anchor" href="#_2-缓存击穿"><span>（2）缓存击穿</span></a></h2><p><strong>什么是缓存击穿？</strong></p><p>缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p><p><strong>缓存击穿危害</strong></p><p>数据库瞬时压力骤增，造成大量请求阻塞。</p><p><strong>如何解决？</strong></p><p><strong>方案一：使用互斥锁（mutex key）</strong></p><p>这种思路比较简单，就是让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223933.png" width="500"></div><br><p>同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。这种情况如何解决？大家可以在留言区讨论。</p><p>如果是分布式应用就需要使用分布式锁。</p><p><strong>方案二：热点数据永不过期</strong></p><p>永不过期实际包含两层意思：</p><ul><li>物理不过期，针对热点key不设置过期时间</li><li>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</li></ul><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018224003.png" width="500"></div><br><p>从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。</p><h2 id="_3-缓存雪崩" tabindex="-1"><a class="header-anchor" href="#_3-缓存雪崩"><span>（3）缓存雪崩</span></a></h2><p><strong>什么是缓存雪崩？</strong></p><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><p><strong>缓存雪崩解决方案</strong></p><p>常用的解决方案有：</p><ul><li>均匀过期</li><li>加互斥锁</li><li>缓存永不过期</li><li>双层缓存策略</li></ul><p>（1）均匀过期</p><p>设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。</p><p>（2）加互斥锁</p><p>跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。</p><p>（3）缓存永不过期</p><p>跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存。</p><p>（4）双层缓存策略</p><p>使用主备两层缓存：</p><p>主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。</p><p>备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。</p><h2 id="_4-缓存预热" tabindex="-1"><a class="header-anchor" href="#_4-缓存预热"><span>（4）缓存预热</span></a></h2><p><strong>什么是缓存预热？</strong></p><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。</p><p>如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。</p><p><strong>缓存预热的操作方法</strong></p><ul><li>数据量不大的时候，工程启动的时候进行加载缓存动作；</li><li>数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</li><li>数据量太大的时候，优先保证热点数据进行提前加载到缓存。</li></ul><h2 id="_5-缓存降级" tabindex="-1"><a class="header-anchor" href="#_5-缓存降级"><span>（5）缓存降级</span></a></h2><p>缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。</p><p>在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。</p><p>降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。</p><h1 id="_8、redis的内存淘汰机制" tabindex="-1"><a class="header-anchor" href="#_8、redis的内存淘汰机制"><span>8、Redis的内存淘汰机制</span></a></h1><p>Redis内存淘汰策略是指当缓存内存不足时，通过淘汰旧数据处理新加入数据选择的策略。</p><p><strong>如何配置最大内存？</strong></p><p><strong>（1）通过配置文件配置</strong></p><p>修改redis.conf配置文件</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>maxmemory 1024mb //设置Redis最大占用内存大小为1024M
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>注意：maxmemory默认配置为0，在64位操作系统下redis最大内存为操作系统剩余内存，在32位操作系统下redis最大内存为3GB。 <strong>（2）通过动态命令配置</strong></p><p>Redis支持运行时通过命令动态修改内存大小：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>127.0.0.1:6379&gt; config set maxmemory 200mb //设置Redis最大占用内存大小为200M
127.0.0.1:6379&gt; config get maxmemory //获取设置的Redis能使用的最大内存大小
1) &quot;maxmemory&quot;
2) &quot;209715200&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>淘汰策略的分类</strong></p><p>Redis最大占用内存用完之后，如果继续添加数据，如何处理这种情况呢？实际上Redis官方已经定义了八种策略来处理这种情况：</p><p><strong>noeviction</strong></p><p>默认策略，对于写请求直接返回错误，不进行淘汰。</p><p><strong>allkeys-lru</strong></p><p>lru(less recently used), 最近最少使用。从所有的key中使用近似LRU算法进行淘汰。</p><p><strong>volatile-lru</strong>lru(less recently used), 最近最少使用。从设置了过期时间的key中使用近似LRU算法进行淘汰。</p><p><strong>allkeys-random</strong></p><p>从所有的key中随机淘汰。</p><p><strong>volatile-random</strong></p><p>从设置了过期时间的key中随机淘汰。</p><p><strong>volatile-ttl</strong></p><p>ttl(time to live)，在设置了过期时间的key中根据key的过期时间进行淘汰，越早过期的越优先被淘汰。</p><p><strong>allkeys-lfu</strong></p><p>lfu(Least Frequently Used)，最少使用频率。从所有的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。</p><p><strong>volatile-lfu</strong></p><p>lfu(Least Frequently Used)，最少使用频率。从设置了过期时间的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。</p><p>注意：当使用volatile-lru、volatile-random、volatile-ttl这三种策略时，如果没有设置过期的key可以被淘汰，则和noeviction一样返回错误。</p><p><strong>LRU算法</strong></p><p>LRU(Least Recently Used)，即最近最少使用，是一种缓存置换算法。在使用内存作为缓存的时候，缓存的大小一般是固定的。当缓存被占满，这个时候继续往缓存里面添加数据，就需要淘汰一部分老的数据，释放内存空间用来存储新的数据。这个时候就可以使用LRU算法了。其核心思想是：如果一个数据在最近一段时间没有被用到，那么将来被使用到的可能性也很小，所以就可以被淘汰掉。</p><p><strong>LRU在Redis中的实现</strong></p><p>Redis使用的是近似LRU算法，它跟常规的LRU算法还不太一样。近似LRU算法通过随机采样法淘汰数据，每次随机出5个（默认）key，从里面淘汰掉最近最少使用的key。</p><p>可以通过maxmemory-samples参数修改采样数量， 如：maxmemory-samples 10</p><p>maxmenory-samples配置的越大，淘汰的结果越接近于严格的LRU算法，但因此耗费的CPU也很高。</p><p>Redis为了实现近似LRU算法，给每个key增加了一个额外增加了一个24bit的字段，用来存储该key最后一次被访问的时间。</p><p><strong>Redis3.0对近似LRU的优化</strong></p><p>Redis3.0对近似LRU算法进行了一些优化。新算法会维护一个候选池（大小为16），池中的数据根据访问时间进行排序，第一次随机选取的key都会放入池中，随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。当放满后，如果有新的key需要放入，则将池中最后访问时间最大（最近被访问）的移除。</p><p>当需要淘汰的时候，则直接从池中选取最近访问时间最小（最久没被访问）的key淘汰掉就行。</p><p><strong>LFU算法</strong></p><p>LFU(Least Frequently Used)，是Redis4.0新加的一种淘汰策略，它的核心思想是根据key的最近被访问的频率进行淘汰，很少被访问的优先被淘汰，被访问的多的则被留下来。</p><p>LFU算法能更好的表示一个key被访问的热度。假如你使用的是LRU算法，一个key很久没有被访问到，只刚刚是偶尔被访问了一次，那么它就被认为是热点数据，不会被淘汰，而有些key将来是很有可能被访问到的则被淘汰了。如果使用LFU算法则不会出现这种情况，因为使用一次并不会使一个key成为热点数据。</p><h1 id="_9、redis有事务机制吗" tabindex="-1"><a class="header-anchor" href="#_9、redis有事务机制吗"><span>9、Redis有事务机制吗？</span></a></h1><ul><li>有事务机制。Redis事务生命周期： 开启事务：使用MULTI开启一个事务</li><li>命令入队列：每次操作的命令都会加入到一个队列中，但命令此时不会真正被执行</li><li>提交事务：使用EXEC命令提交事务，开始顺序执行队列中的命令</li></ul><h1 id="_10、redis事务到底是不是原子性的" tabindex="-1"><a class="header-anchor" href="#_10、redis事务到底是不是原子性的"><span>10、Redis事务到底是不是原子性的？</span></a></h1><p>先看关系型数据库ACID 中关于原子性的定义：**原子性：**一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复(Rollback)到事务开始前的状态，就像这个事务从来没有执行过一样。</p><p>官方文档对事务的定义：</p><ul><li><strong>事务是一个单独的隔离操作</strong>：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li><li><strong>事务是一个原子操作</strong>：事务中的命令要么全部被执行，要么全部都不执行。EXEC 命令负责触发并执行事务中的所有命令：如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。</li></ul><p>官方认为Redis事务是一个原子操作，这是站在执行与否的角度考虑的。但是从ACID原子性定义来看，<strong>严格意义上讲Redis事务是非原子型的</strong>，因为在命令顺序执行过程中，一旦发生命令执行错误Redis是不会停止执行然后回滚数据。</p><h1 id="_11、redis为什么不支持回滚-roll-back" tabindex="-1"><a class="header-anchor" href="#_11、redis为什么不支持回滚-roll-back"><span>11、Redis为什么不支持回滚（roll back）？</span></a></h1><blockquote><p>在事务运行期间虽然Redis命令可能会执行失败，但是Redis依然会执行事务内剩余的命令而不会执行回滚操作。如果你熟悉mysql关系型数据库事务，你会对此非常疑惑，Redis官方的理由如下： 只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。 支持事务回滚能力会导致设计复杂，这与Redis的初衷相违背，Redis的设计目标是功能简化及确保更快的运行速度。</p></blockquote><p>对于官方的这种理由有一个普遍的反对观点：程序有bug怎么办？但其实回归不能解决程序的bug，比如某位粗心的程序员计划更新键A，实际上最后更新了键B，回滚机制是没法解决这种人为错误的。正因为这种人为的错误不太可能进入生产系统，所以官方在设计Redis时选用更加简单和快速的方法，没有实现回滚的机制。</p><h1 id="_12、redis事务相关的命令有哪几个" tabindex="-1"><a class="header-anchor" href="#_12、redis事务相关的命令有哪几个"><span>12、Redis事务相关的命令有哪几个？</span></a></h1><p><strong>（1）WATCH</strong>可以为Redis事务提供 check-and-set （CAS）行为。被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。</p><p><strong>（2）MULTI</strong></p><p>用于开启一个事务，它总是返回OK。MULTI执行之后,客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行，而是被放到一个队列中，当 EXEC命令被调用时， 所有队列中的命令才会被执行。</p><p><strong>（3）UNWATCH</strong></p><p>取消 WATCH 命令对所有 key 的监视，一般用于DISCARD和EXEC命令之前。如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。因为 EXEC 命令会执行事务，因此 WATCH 命令的效果已经产生了；而 DISCARD 命令在取消事务的同时也会取消所有对 key 的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH 了。</p><p><strong>（4）DISCARD</strong></p><p>当执行 DISCARD 命令时， 事务会被放弃， 事务队列会被清空，并且客户端会从事务状态中退出。</p><p><strong>（5）EXEC</strong></p><p>负责触发并执行事务中的所有命令：</p><p>如果客户端成功开启事务后执行EXEC，那么事务中的所有命令都会被执行。</p><p>如果客户端在使用MULTI开启了事务后，却因为断线而没有成功执行EXEC,那么事务中的所有命令都不会被执行。需要特别注意的是：即使事务中有某条/某些命令执行失败了，事务队列中的其他命令仍然会继续执行，Redis不会停止执行事务中的命令，而不会像我们通常使用的关系型数据库一样进行回滚。</p><h1 id="_13、什么是redis主从复制" tabindex="-1"><a class="header-anchor" href="#_13、什么是redis主从复制"><span>13、什么是Redis主从复制？</span></a></h1><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。</p><p><strong>主从复制的作用</strong></p><ul><li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li>高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li></ul><p><strong>主从复制实现原理</strong></p><p>主从复制过程主要可以分为3个阶段：连接建立阶段、数据同步阶段、命令传播阶段。</p><p><strong>连接建立阶段</strong></p><p>该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。</p><p><strong>步骤1：保存主节点信息</strong></p><p>slaveof命令是异步的，在从节点上执行slaveof命令，从节点立即向客户端返回ok，从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。</p><p><strong>步骤2：建立socket连接</strong></p><p>从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。</p><p>从节点为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</p><p>主节点接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</p><p><strong>步骤3：发送ping命令</strong></p><p>从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</p><p>从节点发送ping命令后，可能出现3种情况：</p><p>（1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</p><p>（2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</p><p>（3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</p><p><strong>步骤4：身份验证</strong></p><p>如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p><p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p><p><strong>步骤5：发送从节点端口信息</strong></p><p>身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。</p><p><strong>数据同步阶段</strong></p><p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。</p><p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，后面再讲解这两种复制方式以及psync命令的执行过程，这里不再详述。</p><p><strong>命令传播阶段</strong></p><p>数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p><p>需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p><h1 id="_14、sentinel-哨兵模式-的原理你能讲一下吗" tabindex="-1"><a class="header-anchor" href="#_14、sentinel-哨兵模式-的原理你能讲一下吗"><span>14、Sentinel（哨兵模式）的原理你能讲一下吗？</span></a></h1><p>Redis 的主从复制模式下，一旦主节点由于故障不能提供服务，需要手动将从节点晋升为主节点，同时还要通知客户端更新主节点地址，这种故障处理方式从一定程度上是无法接受的。</p><p>Redis 2.8 以后提供了 Redis Sentinel 哨兵机制来解决这个问题。</p><p>Redis Sentinel 是 Redis 高可用的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的监控、通知、自动故障转移。</p><p>Redis Sentinel架构图如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018221921.png" width="500"></div><br><p><strong>哨兵模式的原理</strong></p><p>哨兵模式的主要作用在于它能够自动完成故障发现和故障转移，并通知客户端，从而实现高可用。哨兵模式通常由一组 Sentinel 节点和一组（或多组）主从复制节点组成。</p><p><strong>心跳机制</strong></p><p>（1）Sentinel与Redis Node</p><p>Redis Sentinel 是一个特殊的 Redis 节点。在哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系，然后 Sentinel 会从主节点上获取所有从节点的信息，之后 Sentinel 会定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。</p><p>（2）Sentinel与Sentinel</p><p>基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 <strong>sentinel</strong>：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。</p><p>通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、以及其余 Sentinel 节点定时发送 ping 命令作为心跳检测， 来确认这些节点是否可达。</p><p><strong>故障转移</strong></p><p>每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为<strong>主观下线</strong>。</p><p>之后该 Sentinel 节点会通过 sentinel ismaster-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断， 当 quorum（法定人数） 个 Sentinel 节点都认为该节点故障时，则执行<strong>客观下线</strong>，即认为该节点已经不可用。这也同时解释了为什么必须需要一组 Sentinel 节点，因为单个 Sentinel 节点很容易对故障状态做出误判。</p><blockquote><p>这里 quorum 的值是我们在哨兵模式搭建时指定的，后文会有说明，通常为 Sentinel节点总数/2+1，即半数以上节点做出主观下线判断就可以执行客观下线。</p></blockquote><p>因为故障转移的工作只需要一个 Sentinel 节点来完成，所以 Sentinel 节点之间会再做一次选举工作， 基于 Raft 算法选出一个 Sentinel 领导者来进行故障转移的工作。</p><p>被选举出的 Sentinel 领导者进行故障转移的具体步骤如下：</p><p>（1）在从节点列表中选出一个节点作为新的主节点</p><ul><li>过滤不健康或者不满足要求的节点；</li><li>选择 slave-priority（优先级）最高的从节点， 如果存在则返回， 不存在则继续；</li><li>选择复制偏移量最大的从节点 ， 如果存在则返回， 不存在则继续；</li><li>选择 runid 最小的从节点。</li></ul><p>（2）Sentinel 领导者节点会对选出来的从节点执行 slaveof no one 命令让其成为主节点。</p><p>（3）Sentinel 领导者节点会向剩余的从节点发送命令，让他们从新的主节点上复制数据。</p><p>（4）Sentinel 领导者会将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。</p><h1 id="_15、cluster-集群-的原理你能讲一下吗" tabindex="-1"><a class="header-anchor" href="#_15、cluster-集群-的原理你能讲一下吗"><span>15、Cluster（集群）的原理你能讲一下吗？</span></a></h1><p>引入Cluster模式的原因： 不管是主从模式还是哨兵模式都只能由一个master在写数据，在海量数据高并发场景，一个节点写数据容易出现瓶颈，引入Cluster模式可以实现多个节点同时写数据。</p><p>Redis-Cluster采用无中心结构，每个节点都保存数据，节点之间互相连接从而知道整个集群状态。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222025.png" width="500"></div><br><p>如图所示Cluster模式其实就是多个主从复制的结构组合起来的，每一个主从复制结构可以看成一个节点，那么上面的Cluster集群中就有三个节点。</p><h1 id="_16、memcache与redis的区别都有哪些" tabindex="-1"><a class="header-anchor" href="#_16、memcache与redis的区别都有哪些"><span>16、Memcache与Redis的区别都有哪些？</span></a></h1><p><strong>存储方式</strong>Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。</p><p>Redis有部份存在硬盘上，这样能保证数据的持久性。</p><p><strong>数据支持类型</strong></p><p>Memcache对数据类型支持相对简单。</p><p>Redis有丰富的数据类型。</p><p><strong>使用底层模型不同</strong></p><p>它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。</p><p>Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p><h1 id="_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来" tabindex="-1"><a class="header-anchor" href="#_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来"><span>17、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</span></a></h1><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>使用keys指令可以扫出指定模式的key列表：
keys pre*
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>这个时候面试官会追问该命令对线上业务有什么影响，直接看下一个问题。</p><h1 id="_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题" tabindex="-1"><a class="header-anchor" href="#_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题"><span>18、如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</span></a></h1><p>redis 的单线程的。keys 指令会导致线 程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时 候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间 会比直接用 keys 指令长。</p><h1 id="_19、如果有大量的key需要设置同一时间过期-一般需要注意什么" tabindex="-1"><a class="header-anchor" href="#_19、如果有大量的key需要设置同一时间过期-一般需要注意什么"><span>19、如果有大量的key需要设置同一时间过期，一般需要注意什么？</span></a></h1><p>如果大量的key过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象(因为redis是单线程的)。严重的话可能会导致服务器雪崩，所以我们一般在过期时间上加一个随机值，让过期时间尽量分散。</p><h1 id="_20、redis常用的客户端有哪些" tabindex="-1"><a class="header-anchor" href="#_20、redis常用的客户端有哪些"><span>20、Redis常用的客户端有哪些？</span></a></h1><p>Jedis：是老牌的Redis的Java实现客户端，提供了比较全面的Redis命令的支持。</p><p>Redisson：实现了分布式和可扩展的Java数据结构。</p><p>Lettuce：高级Redis客户端，用于线程安全同步，异步和响应使用，支持集群，Sentinel，管道和编码器。</p><p><strong>优点：</strong></p><p>Jedis：比较全面的提供了Redis的操作特性。</p><p>Redisson：促使使用者对Redis的关注分离，提供很多分布式相关操作服务，例如，分布式锁，分布式集合，可通过Redis支持延迟队列。</p><p>Lettuce：基于Netty框架的事件驱动的通信层，其方法调用是异步的。Lettuce的API是线程安全的，所以可以操   作单个Lettuce连接来完成各种操作。</p>`,367);function B(R,m){const s=t("ExternalLinkIcon");return r(),o("div",null,[e("ul",null,[e("li",null,[e("ol",null,[e("li",null,[e("a",c,[l("mysql 索引优化"),n(s)])])])])]),E,a(" MarkdownTOC "),g,a(" /MarkdownTOC "),h,e("p",null,[l("查询官方文档（"),e("a",u,[l("https://redis.io/topics/data-types"),n(s)]),l("）可以看到String类型的value值最多支持的长度为512M，所以正确的答案是512M。")]),A])}const y=p(d,[["render",B],["__file","index.html.vue"]]),k=JSON.parse('{"path":"/interview/","title":"1、什么是Redis，Redis有哪些特点？","lang":"en-US","frontmatter":{},"headers":[{"level":3,"title":"mysql 知识点","slug":"mysql-知识点","link":"#mysql-知识点","children":[]},{"level":3,"title":"1. 数据存储","slug":"_1-数据存储","link":"#_1-数据存储","children":[]},{"level":3,"title":"2. 生命周期","slug":"_2-生命周期","link":"#_2-生命周期","children":[]},{"level":3,"title":"3. 数据更新","slug":"_3-数据更新","link":"#_3-数据更新","children":[]},{"level":3,"title":"4. 使用场景","slug":"_4-使用场景","link":"#_4-使用场景","children":[]},{"level":3,"title":"5. 创建语法","slug":"_5-创建语法","link":"#_5-创建语法","children":[]},{"level":3,"title":"6. 作用域","slug":"_6-作用域","link":"#_6-作用域","children":[]},{"level":3,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":3,"title":"1. 读锁（Shared Lock）","slug":"_1-读锁-shared-lock","link":"#_1-读锁-shared-lock","children":[]},{"level":3,"title":"2. 写锁（Exclusive Lock）","slug":"_2-写锁-exclusive-lock","link":"#_2-写锁-exclusive-lock","children":[]},{"level":3,"title":"3. 锁的粒度","slug":"_3-锁的粒度","link":"#_3-锁的粒度","children":[]},{"level":3,"title":"4. 锁的行为","slug":"_4-锁的行为","link":"#_4-锁的行为","children":[]},{"level":3,"title":"5. 使用场景","slug":"_5-使用场景","link":"#_5-使用场景","children":[]},{"level":3,"title":"6. 示例","slug":"_6-示例","link":"#_6-示例","children":[]},{"level":3,"title":"总结","slug":"总结-1","link":"#总结-1","children":[]},{"level":3,"title":"1. 索引优化","slug":"_1-索引优化","link":"#_1-索引优化","children":[]},{"level":3,"title":"2. 查询优化","slug":"_2-查询优化","link":"#_2-查询优化","children":[]},{"level":3,"title":"4. 数据库配置","slug":"_4-数据库配置","link":"#_4-数据库配置","children":[]},{"level":3,"title":"5. 查询分析","slug":"_5-查询分析","link":"#_5-查询分析","children":[]},{"level":3,"title":"6. 分区表","slug":"_6-分区表","link":"#_6-分区表","children":[]},{"level":3,"title":"7. 缓存机制","slug":"_7-缓存机制","link":"#_7-缓存机制","children":[]},{"level":3,"title":"8. 硬件优化","slug":"_8-硬件优化","link":"#_8-硬件优化","children":[]},{"level":3,"title":"总结","slug":"总结-2","link":"#总结-2","children":[]},{"level":2,"title":"REDIS","slug":"redis","link":"#redis","children":[]},{"level":2,"title":"RDB持久化","slug":"rdb持久化","link":"#rdb持久化","children":[]},{"level":2,"title":"AOF持久化","slug":"aof持久化","link":"#aof持久化","children":[]},{"level":2,"title":"RDB和AOF的优缺点","slug":"rdb和aof的优缺点","link":"#rdb和aof的优缺点","children":[]},{"level":2,"title":"（1）缓存穿透","slug":"_1-缓存穿透","link":"#_1-缓存穿透","children":[]},{"level":2,"title":"（2）缓存击穿","slug":"_2-缓存击穿","link":"#_2-缓存击穿","children":[]},{"level":2,"title":"（3）缓存雪崩","slug":"_3-缓存雪崩","link":"#_3-缓存雪崩","children":[]},{"level":2,"title":"（4）缓存预热","slug":"_4-缓存预热","link":"#_4-缓存预热","children":[]},{"level":2,"title":"（5）缓存降级","slug":"_5-缓存降级","link":"#_5-缓存降级","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":83.57,"words":25071},"filePathRelative":"interview/README.md","excerpt":"<ul>\\n<li>\\n<ol>\\n<li><a href=\\"https://tech.meituan.com/2014/06/30/mysql-index.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">mysql 索引优化</a></li>\\n</ol>\\n</li>\\n</ul>\\n<h3>mysql 知识点</h3>\\n<h4>基础部分</h4>\\n<ol>\\n<li>\\n<p>drop、truncate、 delete区别</p>\\n<p>1.DROP TABLE • 作用：这个命令彻底删除整个表，包括表结构、所有数据、索引和权限等。 • 特点：执行速度快，因为不需要逐行删除数据，也无法回滚。 • 使用场景：当你不再需要一个表及其所有相关数据和结构时。</p>\\n<p>2.TRUNCATE TABLE • 作用：删除表中的所有数据，保留表结构。 • 特点： • 执行速度快，类似于DROP，因为它重新创建了表并放弃了所有数据，而无需记录每一行的删除操作。 • 自动提交事务，不可回滚。 •\\n重置自增列（如果有的话）回到初始值 • 使用场景：当你需要清空表的所有数据，但还想保留表结构时。</p>\\n<p>3.DELETE • 作用：删除表中的数据，可以选择性地删除满足特定条件的行。 • 特点： • 可以带条件执行，只删除满足条件的记录。 • 消耗资源较多，特别是数据量大时，因为它需要记录每一条被删除的记录，以便事务可以回滚。 •\\n可以回滚，是事务安全的。 • 使用场景：当你需要删除表中一部分数据，并且希望这个操作是可逆的（通过事务回滚）时。</p>\\n</li>\\n<li>\\n<p>简单总结数据库三范式是什么? 数据库三范式是设计规范，确保数据高效、无冗余： 1.第一范式：确保每列不可分，数据原子性。 2.第二范式：非主键列依赖整个主键。 3.第三范式：非主键列间相互独立，无传递依赖。</p>\\n</li>\\n<li>\\n<p>解释数据库反范式化</p>\\n<p>数据库反范式化是针对数据库规范化的一种设计策略，它通过有意地引入数据冗余、重复的字段或 denormalization 来优化特定的查询性能或简化数据访问</p>\\n<p>1.提升查询速度：通过在表中加入冗余数据，可以避免复杂的联接操作，使得查询只需在一个表中完成，从而减少查询时间和提高效率。 2.简化应用程序代码：应用程序可能无需执行多表联查就能获取所需的所有数据，这可以减少代码复杂度并提高开发效率。\\n3.减少磁盘I/O操作：通过预先计算并存储汇总数据（如计数、总和等），可以减少运行时的计算负担和磁盘读取次数。</p>\\n</li>\\n<li>\\n<p>union和union all有什么不同?</p>\\n<p>UNION 和 UNION ALL 都是用来合并两个或多个SELECT语句的结果集，但它们之间存在一个关键的区别： • 列数和数据类型必须相同：UNION 合并的每个查询，必须返回相同数量的列，且每列的数据类型必须相同或兼容。 •\\nUNION: 会去除结果集中的重复行。在返回结果前，它会对所有结果集进行排序并合并，同时消除完全相同的行。 这个过程需要进行排序操作，因此如果数据量大，可能会比较耗时。 • UNION ALL:\\n不会去除重复行。它直接将各个SELECT语句的结果合并在一起，不做去重处理。 因此，如果源数据中有重复行，在结果集中也会显示出来。由于省去了去重和排序的过程，UNION ALL通常比UNION效率更高。</p>\\n<p>总结来说，如果你需要合并的结果集中不包含重复行，应该使用UNION；如果你不在乎结果集中是否有重复行，并且追求更高的查询效率，应选择UNION ALL。</p>\\n</li>\\n<li>\\n<p>SQL语句执行顺序</p>\\n<p>下面是标准的SQL查询（主要是指SELECT语句）执行的大致步骤，需要注意的是，不同的数据库系统可能有细微差异，但基本遵循以下顺序：</p>\\n<ol>\\n<li>FROM: 首先，确定查询涉及的表。如果有多个表通过JOIN连接，这一步也会解析JOIN条件。</li>\\n<li>ON: 处理JOIN子句中的条件，确定如何连接表。</li>\\n<li>WHERE: 应用WHERE子句中的条件，过滤不符合条件的行。</li>\\n<li>GROUP BY: 将结果集按照GROUP BY子句中的列进行分组。</li>\\n<li>HAVING: 对GROUP BY后的结果应用HAVING子句中的条件，进一步过滤分组。</li>\\n<li>SELECT: 此时处理SELECT列表，计算所有的列表达式。</li>\\n<li>DISTINCT: 如果SELECT语句中包含了DISTINCT关键字，这时会去除重复的行。</li>\\n<li>ORDER BY: 根据ORDER BY子句中的列对结果集进行排序。</li>\\n<li>LIMIT/TOP: 如果语句中有限制返回行数的子句（如MySQL的LIMIT或SQL Server的TOP），此时会应用这些限制。</li>\\n<li>OFFSET/FETCH: 在某些数据库中（如SQL Server的OFFSET-FETCH或MySQL的LIMIT OFFSET），还会在此步处理分页查询。\\n记住，这个顺序是一个逻辑上的概念，实际的数据库引擎内部可能采用更优化的方式来执行查询，不一定严格按这个顺序进行。但理解这个逻辑有助于我们编写更有效的SQL语句。</li>\\n</ol>\\n</li>\\n<li>\\n<p>null的含义</p>\\n<p>在SQL中，NULL值表示一个不确定的或者未知的数据。它与空字符串、零或任何其他值都不相同。以下几点详细解释了NULL的含义： • 缺失数据:\\nNULL常用来表示数据表中的某个字段没有值或者值未知。这与字段为空字符串或数值0有本质区别，因为空字符串和0都是具体的值，而NULL则表示“没有值”。 • 三值逻辑:\\nSQL支持TRUE、FALSE以及UNKNOWN（由NULL代表）的三值逻辑。这意味着在比较操作中，任何涉及NULL的比较（如=, !=, &lt;, &gt;等）都会返回UNKNOWN， 除非使用IS NULL或IS NOT\\nNULL来明确测试NULL值。 • 集合运算: 在UNION操作中，NULL值会被视为相等，即使它们来自不同的源。 • 聚合函数: NULL值在计算如COUNT, AVG, SUM等聚合函数时通常会被忽略，但COUNT(*)\\n会包括NULL值。 简而言之，NULL是SQL中一种特殊的标记，用来表示未知或不可用的信息，它在处理查询时有着特殊的规则。</p>\\n</li>\\n</ol>"}');export{y as comp,k as data};
