import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as t,o as p,c as l,a as n,b as s,d as o,e}from"./app-Dhe8gi3z.js";const r="/docs/assets/images/redis.png",d="/docs/assets/images/redis1.png",c="/docs/assets/images/redis2.png",u="/docs/assets/images/redis3.png",k="/docs/assets/images/redis4.png",g="/docs/assets/images/redis4_1.png",h="/docs/assets/images/redis5.png",m="/docs/assets/images/redis5_1.png",v="/docs/assets/images/redis6.png",y="/docs/assets/images/zk_1.png",b={},R=e(`<h1 id="redis知识点" tabindex="-1"><a class="header-anchor" href="#redis知识点"><span>REDIS知识点</span></a></h1><h2 id="_1、什么是redis-redis有哪些特点" tabindex="-1"><a class="header-anchor" href="#_1、什么是redis-redis有哪些特点"><span>1、什么是Redis，Redis有哪些特点？</span></a></h2><p>Redis全称为：Remote Dictionary Server（远程数据服务），Redis是一种支持key-value等多种数据结构的存储系统。 可用于<strong>缓存</strong>，<strong>事件发布或订阅</strong>，<strong>高速队列</strong>等场景。支持网络，提供<strong>字符串</strong>，<strong>哈希</strong>，<strong>列表</strong>，<strong>队列</strong>，<strong>集合</strong>结构直接存取，基于内存，可持久化。</p><p><strong>特点1：丰富的数据类型</strong></p><p>我们知道很多数据库只能处理一种数据结构：</p><ul><li>传统SQL数据库处理二维关系数据；</li><li>MemCached数据库，键和值都是字符串；</li><li>文档数据库（MongoDB）是由Json/Bson组成的文档。</li></ul><p>当然不是他们这些数据库不好，而是一旦数据库提供数据结构不适合去做某件事情的话，程序写起来就非常麻烦和不自然。</p><p>Redis虽然也是键值对数据库，但是和Memcached不同的是：Redis的值不仅可以是字符串，它还可以是其他五中数据机构中的任意一种。通过选用不同的数据结构，用户可以使用Redis解决各种各样的问题，使用Redis，你碰到一个问题，首先会想到是选用那种数据结构把哪些功能问题解决掉，有了多样的数据结构，方便你解决问题。</p><p><strong>特点2：内存存储</strong></p><p>数据库有两种：一种是硬盘数据库，一种是内存数据库。</p><p>硬盘数据库是把值存储在硬盘上，在内存中就存储一下索引，当硬盘数据库想访问硬盘的值时，它先在内存里找到索引，然后再找值。问题在于，在读取和写入硬盘的时候，如果读写比较多的时候，它会把硬盘的IO功能堵死。</p><p>内存存储是讲所有的数据都存储在内存里面，数据读取和写入速度非常快。</p><p><strong>特点3：持久化功能</strong></p><p>将数据存储在内存里面的数据保存到硬盘中，保证数据安全，方便进行数据备份和恢复。</p><h2 id="_2、redis有哪些数据结构" tabindex="-1"><a class="header-anchor" href="#_2、redis有哪些数据结构"><span>2、Redis有哪些数据结构？</span></a></h2><p>Redis是key-value数据库，key的类型只能是String，但是value的数据类型就比较丰富了，主要包括五种：</p><ul><li>String</li><li>Hash</li><li>List</li><li>Set</li><li>Sorted Set</li></ul><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222748.png" width="300"></div><br><p><strong>（1）String字符串</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>SET KEY_NAME VALUE
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。</p><p><strong>（2）Hash哈希</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>HSET KEY_NAME FIELD VALUE
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis hash 是一个键值(key=&gt;value)对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。</p><p><strong>（3）List列表</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>//在 key 对应 list 的头部添加字符串元素
LPUSH KEY_NAME VALUE1.. VALUEN
//在 key 对应 list 的尾部添加字符串元素
RPUSH KEY_NAME VALUE1..VALUEN
//对应 list 中删除 count 个和 value 相同的元素
LREM KEY_NAME COUNT VALUE
//返回 key 对应 list 的长度
LLEN KEY_NAME 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Redis 列表是简单的字符串列表，按照插入顺序排序。 可以添加一个元素到列表的头部（左边）或者尾部（右边）</p><p><strong>（4）Set集合</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>SADD KEY_NAME VALUE1...VALUEn
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。</p><p><strong>（5）Sorted Set有序集合</strong></p><p>语法</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>ZADD KEY_NAME SCORE1 VALUE1.. SCOREN VALUEN
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。</p><p>redis正是通过分数来为集合中的成员进行从小到大的排序。</p><p>zset的成员是唯一的,但分数(score)却可以重复。</p><h2 id="_3、一个字符串类型的值能存储最大容量是多少" tabindex="-1"><a class="header-anchor" href="#_3、一个字符串类型的值能存储最大容量是多少"><span>3、一个字符串类型的值能存储最大容量是多少？</span></a></h2>`,42),f={href:"https://redis.io/topics/data-types",target:"_blank",rel:"noopener noreferrer"},_=e(`<div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222920.jpeg" width=""></div><br><h2 id="_4、能说一下redis每种数据结构的使用场景吗" tabindex="-1"><a class="header-anchor" href="#_4、能说一下redis每种数据结构的使用场景吗"><span>4、能说一下Redis每种数据结构的使用场景吗？</span></a></h2><p><strong>（1）String的使用场景</strong></p><p>字符串类型的使用场景：信息缓存、计数器、分布式锁等等。</p><p>常用命令：get/set/del/incr/decr/incrby/decrby</p><p><strong>实战场景1：记录每一个用户的访问次数，或者记录每一个商品的浏览次数</strong></p><p>方案：</p><p>常用键名： userid:pageview 或者 pageview:userid，如果一个用户的id为123，那对应的redis key就为pageview:123，value就为用户的访问次数，增加次数可以使用命令：incr。</p><p>使用理由：每一个用户访问次数或者商品浏览次数的修改是很频繁的，如果使用mysql这种文件系统频繁修改会造成mysql压力，效率也低。而使用redis的好处有二：使用内存，很快；单线程，所以无竞争，数据不会被改乱。</p><p><strong>实战场景2：缓存频繁读取，但是不常修改的信息，如用户信息，视频信息</strong></p><p>方案：</p><p>业务逻辑上：先从redis读取，有值就从redis读取，没有则从mysql读取，并写一份到redis中作为缓存，注意要设置过期时间。</p><p>键值设计上：</p><p>直接将用户一条mysql记录做序列化(通常序列化为json)作为值，userInfo:userid 作为key，键名如：userInfo:123，value存储对应用户信息的json串。如 key为：&quot;user:id :name:1&quot;, value为&quot;{&quot;name&quot;:&quot;leijia&quot;,&quot;age&quot;:18}&quot;。</p><p><strong>实战场景3：限定某个ip特定时间内的访问次数</strong></p><p>方案：</p><p>用key记录IP，value记录访问次数，同时key的过期时间设置为60秒，如果key过期了则重新设置，否则进行判断，当一分钟内访问超过100次，则禁止访问。</p><p><strong>实战场景4:分布式session</strong></p><p>我们知道session是以文件的形式保存在服务器中的；如果你的应用做了负载均衡，将网站的项目放在多个服务器上，当用户在服务器A上进行登陆，session文件会写在A服务器；当用户跳转页面时，请求被分配到B服务器上的时候，就找不到这个session文件，用户就要重新登陆。</p><p>如果想要多个服务器共享一个session，可以将session存放在redis中，redis可以独立于所有负载均衡服务器，也可以放在其中一台负载均衡服务器上；但是所有应用所在的服务器连接的都是同一个redis服务器。</p><p><strong>（2）Hash的使用场景</strong></p><p>以购物车为例子，用户id设置为key，那么购物车里所有的商品就是用户key对应的值了，每个商品有id和购买数量，对应hash的结构就是商品id为field，商品数量为value。如图所示：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223018.jpeg" width="200"></div><br><p>如果将商品id和商品数量序列化成json字符串，那么也可以用上面讲的string类型存储。下面对比一下这两种数据结构：</p><table><thead><tr><th style="text-align:left;">对比项</th><th style="text-align:left;">string（json）</th><th style="text-align:left;">hash</th></tr></thead><tbody><tr><td style="text-align:left;">效率</td><td style="text-align:left;">很高</td><td style="text-align:left;">高</td></tr><tr><td style="text-align:left;">容量</td><td style="text-align:left;">低</td><td style="text-align:left;">低</td></tr><tr><td style="text-align:left;">灵活性</td><td style="text-align:left;"><strong>低</strong></td><td style="text-align:left;">高</td></tr><tr><td style="text-align:left;">序列化</td><td style="text-align:left;">简单</td><td style="text-align:left;"><strong>复杂</strong></td></tr></tbody></table><p>总结一下：</p><p>当对象的某个属性需要频繁修改时，不适合用string+json，因为它不够灵活，每次修改都需要重新将整个对象序列化并赋值；如果使用hash类型，则可以针对某个属性单独修改，没有序列化，也不需要修改整个对象。比如，商品的价格、销量、关注数、评价数等可能经常发生变化的属性，就适合存储在hash类型里。</p><p><strong>（3）List的使用场景</strong></p><p>列表本质是一个有序的，元素可重复的队列。</p><p><strong>实战场景：定时排行榜</strong></p><p>list类型的lrange命令可以分页查看队列中的数据。可将每隔一段时间计算一次的排行榜存储在list类型中，如QQ音乐内地排行榜，每周计算一次存储再list类型中，访问接口时通过page和size分页转化成lrange命令获取排行榜数据。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223052.jpeg" width="200"></div><br><p>但是，并不是所有的排行榜都能用list类型实现，只有定时计算的排行榜才适合使用list类型存储，与定时计算的排行榜相对应的是实时计算的排行榜，list类型不能支持实时计算的排行榜，下面介绍有序集合sorted set的应用场景时会详细介绍实时计算的排行榜的实现。</p><p><strong>（4）Set的使用场景</strong></p><p>集合的特点是无序性和确定性（不重复）。</p><p><strong>实战场景：收藏夹</strong></p><p>例如QQ音乐中如果你喜欢一首歌，点个『喜欢』就会将歌曲放到个人收藏夹中，每一个用户做一个收藏的集合，每个收藏的集合存放用户收藏过的歌曲id。</p><p>key为用户id，value为歌曲id的集合。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223310.jpeg" width="200"></div><br><p><strong>（5）Sorted Set的使用场景</strong></p><p>有序集合的特点是有序，无重复值。与set不同的是sorted set每个元素都会关联一个score属性，redis正是通过score来为集合中的成员进行从小到大的排序。</p><p><strong>实战场景：实时排行榜</strong></p><p>QQ音乐中有多种实时榜单，比如飙升榜、热歌榜、新歌榜，可以用redis key存储榜单类型，score为点击量，value为歌曲id，用户每点击一首歌曲会更新redis数据，sorted set会依据score即点击量将歌曲id排序。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223348.jpeg" width="200"></div><br><h2 id="_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗" tabindex="-1"><a class="header-anchor" href="#_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗"><span>5、Redis如何做持久化的?能说一下RDB和AOF的实现原理吗?</span></a></h2><p><strong>什么是持久化？</strong></p><p>持久化（Persistence），即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223421.png" width=""></div><br><p>还可以从如下两个层面简单的理解持久化 ：</p><ul><li>应用层：如果关闭(shutdown)你的应用然后重新启动则先前的数据依然存在。</li><li>系统层：如果关闭(shutdown)你的系统（电脑）然后重新启动则先前的数据依然存在。</li></ul><p><strong>Redis为什么要持久化？</strong></p><p>Redis是内存数据库，为了保证效率所有的操作都是在内存中完成。数据都是缓存在内存中，当你重启系统或者关闭系统，之前缓存在内存中的数据都会丢失再也不能找回。因此为了避免这种情况，Redis需要实现持久化将内存中的数据存储起来。</p><p><strong>Redis如何实现持久化？</strong></p><p>Redis官方提供了不同级别的持久化方式：</p><ul><li>RDB持久化：能够在指定的时间间隔能对你的数据进行快照存储。</li><li>AOF持久化：记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。</li><li>不使用持久化：如果你只希望你的数据在服务器运行的时候存在，你也可以选择不使用任何持久化方式。</li><li>同时开启RDB和AOF：你也可以同时开启两种持久化方式，在这种情况下当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。</li></ul><p>这么多持久化方式我们应该怎么选？在选择之前我们需要搞清楚每种持久化方式的区别以及各自的优劣势。</p><h3 id="rdb持久化" tabindex="-1"><a class="header-anchor" href="#rdb持久化"><span>RDB持久化</span></a></h3><p>RDB(Redis Database)持久化是把当前内存数据生成快照保存到硬盘的过程，触发RDB持久化过程分为<strong>手动触发</strong>和<strong>自动触发</strong>。</p><p>（1）手动触发</p><p>手动触发对应save命令，会阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。</p><p>（2）自动触发</p><p>自动触发对应bgsave命令，Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</p><p>在redis.conf配置文件中可以配置：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>save &lt;seconds&gt; &lt;changes&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>表示xx秒内数据修改xx次时自动触发bgsave。 如果想关闭自动触发，可以在save命令后面加一个空串，即：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>save &quot;&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>还有其他常见可以触发bgsave，如：</p><ul><li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点。</li><li>默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则 自动执行bgsave。</li></ul><p><strong>bgsave工作机制</strong></p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223529.png" width="300"></div><br><p>（1）执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进 程，如RDB/AOF子进程，如果存在，bgsave命令直接返回。</p><p>（2）父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞，通 过info stats命令查看latest_fork_usec选项，可以获取最近一个fork操作的耗时，单位为微秒</p><p>（3）父进程fork完成后，bgsave命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令。</p><p>（4）子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行lastsave命令可以获取最后一次生成RDB的 时间，对应info统计的rdb_last_save_time选项。</p><p>（5）进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence下的rdb_*相关选项。</p><p>-- RDB持久化完 --</p><h3 id="aof持久化" tabindex="-1"><a class="header-anchor" href="#aof持久化"><span>AOF持久化</span></a></h3><p>AOF（append only file）持久化：以独立日志的方式记录每次写命令， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决了数据持久化的实时性，目前已经是Redis持久化的主流方式。</p><p><strong>AOF持久化工作机制</strong></p><p>开启AOF功能需要配置：appendonly yes，默认不开启。</p><p>AOF文件名 通过appendfilename配置设置，默认文件名是appendonly.aof。保存路径同 RDB持久化方式一致，通过dir配置指定。</p><p>AOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写（rewrite）、重启加载 （load）。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223557.png" width="200"></div><br><p>（1）所有的写入命令会追加到aof_buf（缓冲区）中。</p><p>（2）AOF缓冲区根据对应的策略向硬盘做同步操作。</p><p>AOF为什么把命令追加到aof_buf中？Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡。</p><p>（3）随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的。</p><p>（4）当Redis服务器重启时，可以加载AOF文件进行数据恢复。</p><p><strong>AOF重写（rewrite）机制</strong></p><p>重写的目的：</p><ul><li>减小AOF文件占用空间；</li><li>更小的AOF 文件可以更快地被Redis加载恢复。</li></ul><p>AOF重写可以分为手动触发和自动触发：</p><ul><li>手动触发：直接调用bgrewriteaof命令。</li><li>自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。</li></ul><p>auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认 为64MB。</p><p>auto-aof-rewrite-percentage：代表当前AOF文件空间 （aof_current_size）和上一次重写后AOF文件空间（aof_base_size）的比值。</p><p>自动触发时机</p><p>当aof_current_size&gt;auto-aof-rewrite-minsize 并且（aof_current_size-aof_base_size）/aof_base_size&gt;=auto-aof-rewritepercentage。</p><p>其中aof_current_size和aof_base_size可以在info Persistence统计信息中查看。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223632.png" width="300"></div><br><p>AOF文件重写后为什么会变小？</p><p>（1）旧的AOF文件含有无效的命令，如：del key1， hdel key2等。重写只保留最终数据的写入命令。</p><p>（2）多条命令可以合并，如lpush list a，lpush list b，lpush list c可以直接转化为lpush list a b c。</p><p><strong>AOF文件数据恢复</strong></p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223700.png" width="300"></div><br><p>数据恢复流程说明：</p><p>（1）AOF持久化开启且存在AOF文件时，优先加载AOF文件。</p><p>（2）AOF关闭或者AOF文件不存在时，加载RDB文件。</p><p>（3）加载AOF/RDB文件成功后，Redis启动成功。</p><p>（4）AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。</p><p>-- AOF持久化完 --</p><h3 id="rdb和aof的优缺点" tabindex="-1"><a class="header-anchor" href="#rdb和aof的优缺点"><span>RDB和AOF的优缺点</span></a></h3><p><strong>RDB优点</strong></p><ul><li>RDB 是一个非常紧凑的文件,它保存了某个时间点的数据集,非常适用于数据集的备份,比如你可以在每个小时报保存一下过去24小时内的数据,同时每天保存过去30天的数据,这样即使出了问题你也可以根据需求恢复到不同版本的数据集。</li><li>RDB 是一个紧凑的单一文件,很方便传送到另一个远端数据中心，非常适用于灾难恢复。</li><li>RDB 在保存 RDB 文件时父进程唯一需要做的就是 fork 出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他 IO 操作，所以 RDB 持久化方式可以最大化 Redis 的性能。</li><li>与AOF相比,在恢复大的数据集的时候，RDB 方式会更快一些。</li></ul><p><strong>AOF优点</strong></p><ul><li>你可以使用不同的 fsync 策略：无 fsync、每秒 fsync 、每次写的时候 fsync .使用默认的每秒 fsync 策略, Redis 的性能依然很好( fsync 是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据。</li><li>AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题。</li><li>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li><li>AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。</li></ul><p><strong>RDB缺点</strong></p><ul><li>Redis 要完整的保存整个数据集是一个比较繁重的工作,你通常会每隔5分钟或者更久做一次完整的保存,万一在 Redis 意外宕机,你可能会丢失几分钟的数据。</li><li>RDB 需要经常 fork 子进程来保存数据集到硬盘上,当数据集比较大的时候, fork 的过程是非常耗时的,可能会导致 Redis 在一些毫秒级内不能响应客户端的请求。</li></ul><p><strong>AOF缺点</strong></p><ul><li>对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。</li><li>数据恢复（load）时AOF比RDB慢，通常RDB 可以提供更有保证的最大延迟时间。</li></ul><p><strong>RDB和AOF简单对比总结</strong></p><p>RDB优点：</p><ul><li>RDB 是紧凑的二进制文件，比较适合备份，全量复制等场景</li><li>RDB 恢复数据远快于 AOF</li></ul><p>RDB缺点：</p><ul><li>RDB 无法实现实时或者秒级持久化；</li><li>新老版本无法兼容 RDB 格式。</li></ul><p>AOF优点：</p><ul><li>可以更好地保护数据不丢失；</li><li>appen-only 模式写入性能比较高；</li><li>适合做灾难性的误删除紧急恢复。</li></ul><p>AOF缺点：</p><ul><li>对于同一份文件，AOF 文件要比 RDB 快照大；</li><li>AOF 开启后，会对写的 QPS 有所影响，相对于 RDB 来说 写 QPS 要下降；</li><li>数据库恢复比较慢， 不合适做冷备。</li></ul><h2 id="_6、讲解一下redis的线程模型" tabindex="-1"><a class="header-anchor" href="#_6、讲解一下redis的线程模型"><span>6、讲解一下Redis的线程模型？</span></a></h2><p>redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。</p><p>如果面试官继续追问为啥 redis 单线程模型也能效率这么高？</p><ul><li>纯内存操作</li><li>核心是基于非阻塞的 IO 多路复用机制</li><li>单线程反而避免了多线程的频繁上下文切换问题</li></ul><h2 id="_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么" tabindex="-1"><a class="header-anchor" href="#_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么"><span>7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么？</span></a></h2><p>在实际生产环境中有时会遇到缓存穿透、缓存击穿、缓存雪崩等异常场景，为了避免异常带来巨大损失，我们需要了解每种异常发生的原因以及解决方案，帮助提升系统可靠性和高可用。</p><h3 id="_1-缓存穿透" tabindex="-1"><a class="header-anchor" href="#_1-缓存穿透"><span>（1）缓存穿透</span></a></h3><p><strong>什么是缓存穿透？</strong></p><p>缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。</p><p>如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统。</p><p><strong>缓存穿透常用的解决方案</strong></p><p><strong>（1）布隆过滤器（推荐）</strong></p><p>布隆过滤器（Bloom Filter，简称BF）由Burton Howard Bloom在1970年提出，是一种空间效率高的概率型数据结构。</p><p><strong>布隆过滤器专门用来检测集合中是否存在特定的元素。</strong></p><p>如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：</p><ul><li>采用线性表存储，查找时间复杂度为O(N)</li><li>采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为O(logN)</li><li>采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要O[log(n/m)]</li></ul><p>当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。接下来看一下布隆过滤器如何解决这个问题。</p><p><strong>布隆过滤器设计思想</strong></p><p>布隆过滤器由一个长度为m比特的位数组（bit array）与k个哈希函数（hash function）组成的数据结构。位数组初始化均为0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。</p><p>当要向布隆过滤器中插入一个元素时，该元素经过k个哈希函数计算产生k个哈希值，以哈希值作为位数组中的下标，将所有k个对应的比特值由0置为1。</p><p>当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后检查对应的k个比特值：如果有任意一个比特为0，表明该元素一定不在集合中；如果所有比特均为1，表明该集合有可能性在集合中。为什么不是一定在集合中呢？因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。</p><p>总结一下：布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。</p><p>举个例子：下图是一个布隆过滤器，共有18个比特位，3个哈希函数。集合中三个元素x，y，z通过三个哈希函数散列到不同的比特位，并将比特位置为1。当查询元素w时，通过三个哈希函数计算，发现有一个比特位的值为0，可以肯定认为该元素不在集合中。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223743.png" width="500"></div><br><p><strong>布隆过滤器优缺点</strong></p><p>优点：</p><ul><li>节省空间：不需要存储数据本身，只需要存储数据对应hash比特位</li><li>时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数</li></ul><p>缺点：</p><ul><li>存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数</li><li>不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了</li></ul><p><strong>布隆过滤器适用场景</strong></p><ul><li>爬虫系统url去重</li><li>垃圾邮件过滤</li><li>黑名单</li></ul><p><strong>（2）返回空对象</strong></p><p>当缓存未命中，查询持久层也为空，可以将返回的空对象写到缓存中，这样下次请求该key时直接从缓存中查询返回空对象，请求不会落到持久层数据库。为了避免存储过多空对象，通常会给空对象设置一个过期时间。</p><p>这种方法会存在两个问题：</p><ul><li>如果有大量的key穿透，缓存空对象会占用宝贵的内存空间。</li><li>空对象的key设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。</li></ul><h3 id="_2-缓存击穿" tabindex="-1"><a class="header-anchor" href="#_2-缓存击穿"><span>（2）缓存击穿</span></a></h3><p><strong>什么是缓存击穿？</strong></p><p>缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p><p><strong>缓存击穿危害</strong></p><p>数据库瞬时压力骤增，造成大量请求阻塞。</p><p><strong>如何解决？</strong></p><p><strong>方案一：使用互斥锁（mutex key）</strong></p><p>这种思路比较简单，就是让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018223933.png" width="500"></div><br><p>同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。这种情况如何解决？大家可以在留言区讨论。</p><p>如果是分布式应用就需要使用分布式锁。</p><p><strong>方案二：热点数据永不过期</strong></p><p>永不过期实际包含两层意思：</p><ul><li>物理不过期，针对热点key不设置过期时间</li><li>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</li></ul><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018224003.png" width="500"></div><br><p>从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。</p><h3 id="_3-缓存雪崩" tabindex="-1"><a class="header-anchor" href="#_3-缓存雪崩"><span>（3）缓存雪崩</span></a></h3><p><strong>什么是缓存雪崩？</strong></p><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p><p><strong>缓存雪崩解决方案</strong></p><p>常用的解决方案有：</p><ul><li>均匀过期</li><li>加互斥锁</li><li>缓存永不过期</li><li>双层缓存策略</li></ul><p>（1）均匀过期</p><p>设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。</p><p>（2）加互斥锁</p><p>跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。</p><p>（3）缓存永不过期</p><p>跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存。</p><p>（4）双层缓存策略</p><p>使用主备两层缓存：</p><p>主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。</p><p>备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。</p><h3 id="_4-缓存预热" tabindex="-1"><a class="header-anchor" href="#_4-缓存预热"><span>（4）缓存预热</span></a></h3><p><strong>什么是缓存预热？</strong></p><p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。</p><p>如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。</p><p><strong>缓存预热的操作方法</strong></p><ul><li>数据量不大的时候，工程启动的时候进行加载缓存动作；</li><li>数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</li><li>数据量太大的时候，优先保证热点数据进行提前加载到缓存。</li></ul><h3 id="_5-缓存降级" tabindex="-1"><a class="header-anchor" href="#_5-缓存降级"><span>（5）缓存降级</span></a></h3><p>缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。</p><p>在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。</p><p>降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。</p><h2 id="_8、redis的内存淘汰机制" tabindex="-1"><a class="header-anchor" href="#_8、redis的内存淘汰机制"><span>8、Redis的内存淘汰机制</span></a></h2><p>Redis内存淘汰策略是指当缓存内存不足时，通过淘汰旧数据处理新加入数据选择的策略。</p><p><strong>如何配置最大内存？</strong></p><p><strong>（1）通过配置文件配置</strong></p><p>修改redis.conf配置文件</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>maxmemory 1024mb //设置Redis最大占用内存大小为1024M
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>注意：maxmemory默认配置为0，在64位操作系统下redis最大内存为操作系统剩余内存，在32位操作系统下redis最大内存为3GB。 <strong>（2）通过动态命令配置</strong></p><p>Redis支持运行时通过命令动态修改内存大小：</p><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>127.0.0.1:6379&gt; config set maxmemory 200mb //设置Redis最大占用内存大小为200M
127.0.0.1:6379&gt; config get maxmemory //获取设置的Redis能使用的最大内存大小
1) &quot;maxmemory&quot;
2) &quot;209715200&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>淘汰策略的分类</strong></p><p>Redis最大占用内存用完之后，如果继续添加数据，如何处理这种情况呢？实际上Redis官方已经定义了八种策略来处理这种情况：</p><p><strong>noeviction</strong></p><p>默认策略，对于写请求直接返回错误，不进行淘汰。</p><p><strong>allkeys-lru</strong></p><p>lru(less recently used), 最近最少使用。从所有的key中使用近似LRU算法进行淘汰。</p><p><strong>volatile-lru</strong>lru(less recently used), 最近最少使用。从设置了过期时间的key中使用近似LRU算法进行淘汰。</p><p><strong>allkeys-random</strong></p><p>从所有的key中随机淘汰。</p><p><strong>volatile-random</strong></p><p>从设置了过期时间的key中随机淘汰。</p><p><strong>volatile-ttl</strong></p><p>ttl(time to live)，在设置了过期时间的key中根据key的过期时间进行淘汰，越早过期的越优先被淘汰。</p><p><strong>allkeys-lfu</strong></p><p>lfu(Least Frequently Used)，最少使用频率。从所有的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。</p><p><strong>volatile-lfu</strong></p><p>lfu(Least Frequently Used)，最少使用频率。从设置了过期时间的key中使用近似LFU算法进行淘汰。从Redis4.0开始支持。</p><p>注意：当使用volatile-lru、volatile-random、volatile-ttl这三种策略时，如果没有设置过期的key可以被淘汰，则和noeviction一样返回错误。</p><p><strong>LRU算法</strong></p><p>LRU(Least Recently Used)，即最近最少使用，是一种缓存置换算法。在使用内存作为缓存的时候，缓存的大小一般是固定的。当缓存被占满，这个时候继续往缓存里面添加数据，就需要淘汰一部分老的数据，释放内存空间用来存储新的数据。这个时候就可以使用LRU算法了。其核心思想是：如果一个数据在最近一段时间没有被用到，那么将来被使用到的可能性也很小，所以就可以被淘汰掉。</p><p><strong>LRU在Redis中的实现</strong></p><p>Redis使用的是近似LRU算法，它跟常规的LRU算法还不太一样。近似LRU算法通过随机采样法淘汰数据，每次随机出5个（默认）key，从里面淘汰掉最近最少使用的key。</p><p>可以通过maxmemory-samples参数修改采样数量， 如：maxmemory-samples 10</p><p>maxmenory-samples配置的越大，淘汰的结果越接近于严格的LRU算法，但因此耗费的CPU也很高。</p><p>Redis为了实现近似LRU算法，给每个key增加了一个额外增加了一个24bit的字段，用来存储该key最后一次被访问的时间。</p><p><strong>Redis3.0对近似LRU的优化</strong></p><p>Redis3.0对近似LRU算法进行了一些优化。新算法会维护一个候选池（大小为16），池中的数据根据访问时间进行排序，第一次随机选取的key都会放入池中，随后每次随机选取的key只有在访问时间小于池中最小的时间才会放入池中，直到候选池被放满。当放满后，如果有新的key需要放入，则将池中最后访问时间最大（最近被访问）的移除。</p><p>当需要淘汰的时候，则直接从池中选取最近访问时间最小（最久没被访问）的key淘汰掉就行。</p><p><strong>LFU算法</strong></p><p>LFU(Least Frequently Used)，是Redis4.0新加的一种淘汰策略，它的核心思想是根据key的最近被访问的频率进行淘汰，很少被访问的优先被淘汰，被访问的多的则被留下来。</p><p>LFU算法能更好的表示一个key被访问的热度。假如你使用的是LRU算法，一个key很久没有被访问到，只刚刚是偶尔被访问了一次，那么它就被认为是热点数据，不会被淘汰，而有些key将来是很有可能被访问到的则被淘汰了。如果使用LFU算法则不会出现这种情况，因为使用一次并不会使一个key成为热点数据。</p><h2 id="_9、redis有事务机制吗" tabindex="-1"><a class="header-anchor" href="#_9、redis有事务机制吗"><span>9、Redis有事务机制吗？</span></a></h2><ul><li>有事务机制。Redis事务生命周期： 开启事务：使用MULTI开启一个事务</li><li>命令入队列：每次操作的命令都会加入到一个队列中，但命令此时不会真正被执行</li><li>提交事务：使用EXEC命令提交事务，开始顺序执行队列中的命令</li></ul><h2 id="_10、redis事务到底是不是原子性的" tabindex="-1"><a class="header-anchor" href="#_10、redis事务到底是不是原子性的"><span>10、Redis事务到底是不是原子性的？</span></a></h2><p>先看关系型数据库ACID 中关于原子性的定义：**原子性：**一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复(Rollback)到事务开始前的状态，就像这个事务从来没有执行过一样。</p><p>官方文档对事务的定义：</p><ul><li><strong>事务是一个单独的隔离操作</strong>：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li><li><strong>事务是一个原子操作</strong>：事务中的命令要么全部被执行，要么全部都不执行。EXEC 命令负责触发并执行事务中的所有命令：如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。</li></ul><p>官方认为Redis事务是一个原子操作，这是站在执行与否的角度考虑的。但是从ACID原子性定义来看，<strong>严格意义上讲Redis事务是非原子型的</strong>，因为在命令顺序执行过程中，一旦发生命令执行错误Redis是不会停止执行然后回滚数据。</p><h2 id="_11、redis为什么不支持回滚-roll-back" tabindex="-1"><a class="header-anchor" href="#_11、redis为什么不支持回滚-roll-back"><span>11、Redis为什么不支持回滚（roll back）？</span></a></h2><blockquote><p>在事务运行期间虽然Redis命令可能会执行失败，但是Redis依然会执行事务内剩余的命令而不会执行回滚操作。如果你熟悉mysql关系型数据库事务，你会对此非常疑惑，Redis官方的理由如下： 只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。 支持事务回滚能力会导致设计复杂，这与Redis的初衷相违背，Redis的设计目标是功能简化及确保更快的运行速度。</p></blockquote><p>对于官方的这种理由有一个普遍的反对观点：程序有bug怎么办？但其实回归不能解决程序的bug，比如某位粗心的程序员计划更新键A，实际上最后更新了键B，回滚机制是没法解决这种人为错误的。正因为这种人为的错误不太可能进入生产系统，所以官方在设计Redis时选用更加简单和快速的方法，没有实现回滚的机制。</p><h2 id="_12、redis事务相关的命令有哪几个" tabindex="-1"><a class="header-anchor" href="#_12、redis事务相关的命令有哪几个"><span>12、Redis事务相关的命令有哪几个？</span></a></h2><p><strong>（1）WATCH</strong>可以为Redis事务提供 check-and-set （CAS）行为。被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。</p><p><strong>（2）MULTI</strong></p><p>用于开启一个事务，它总是返回OK。MULTI执行之后,客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行，而是被放到一个队列中，当 EXEC命令被调用时， 所有队列中的命令才会被执行。</p><p><strong>（3）UNWATCH</strong></p><p>取消 WATCH 命令对所有 key 的监视，一般用于DISCARD和EXEC命令之前。如果在执行 WATCH 命令之后， EXEC 命令或 DISCARD 命令先被执行了的话，那么就不需要再执行 UNWATCH 了。因为 EXEC 命令会执行事务，因此 WATCH 命令的效果已经产生了；而 DISCARD 命令在取消事务的同时也会取消所有对 key 的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH 了。</p><p><strong>（4）DISCARD</strong></p><p>当执行 DISCARD 命令时， 事务会被放弃， 事务队列会被清空，并且客户端会从事务状态中退出。</p><p><strong>（5）EXEC</strong></p><p>负责触发并执行事务中的所有命令：</p><p>如果客户端成功开启事务后执行EXEC，那么事务中的所有命令都会被执行。</p><p>如果客户端在使用MULTI开启了事务后，却因为断线而没有成功执行EXEC,那么事务中的所有命令都不会被执行。需要特别注意的是：即使事务中有某条/某些命令执行失败了，事务队列中的其他命令仍然会继续执行，Redis不会停止执行事务中的命令，而不会像我们通常使用的关系型数据库一样进行回滚。</p><h2 id="_13、什么是redis主从复制" tabindex="-1"><a class="header-anchor" href="#_13、什么是redis主从复制"><span>13、什么是Redis主从复制？</span></a></h2><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。</p><p><strong>主从复制的作用</strong></p><ul><li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li>故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li>负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li>高可用基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li></ul><p><strong>主从复制实现原理</strong></p><p>主从复制过程主要可以分为3个阶段：连接建立阶段、数据同步阶段、命令传播阶段。</p><p><strong>连接建立阶段</strong></p><p>该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。</p><p><strong>步骤1：保存主节点信息</strong></p><p>slaveof命令是异步的，在从节点上执行slaveof命令，从节点立即向客户端返回ok，从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。</p><p><strong>步骤2：建立socket连接</strong></p><p>从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。</p><p>从节点为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。</p><p>主节点接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。</p><p><strong>步骤3：发送ping命令</strong></p><p>从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。</p><p>从节点发送ping命令后，可能出现3种情况：</p><p>（1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。</p><p>（2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。</p><p>（3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。</p><p><strong>步骤4：身份验证</strong></p><p>如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。</p><p>如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。</p><p><strong>步骤5：发送从节点端口信息</strong></p><p>身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。</p><p><strong>数据同步阶段</strong></p><p>主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。</p><p>数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，后面再讲解这两种复制方式以及psync命令的执行过程，这里不再详述。</p><p><strong>命令传播阶段</strong></p><p>数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p><p>需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。</p><h2 id="_14、sentinel-哨兵模式-的原理你能讲一下吗" tabindex="-1"><a class="header-anchor" href="#_14、sentinel-哨兵模式-的原理你能讲一下吗"><span>14、Sentinel（哨兵模式）的原理你能讲一下吗？</span></a></h2><p>Redis 的主从复制模式下，一旦主节点由于故障不能提供服务，需要手动将从节点晋升为主节点，同时还要通知客户端更新主节点地址，这种故障处理方式从一定程度上是无法接受的。</p><p>Redis 2.8 以后提供了 Redis Sentinel 哨兵机制来解决这个问题。</p><p>Redis Sentinel 是 Redis 高可用的实现方案。Sentinel 是一个管理多个 Redis 实例的工具，它可以实现对 Redis 的监控、通知、自动故障转移。</p><p>Redis Sentinel架构图如下：</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018221921.png" width="500"></div><br><p><strong>哨兵模式的原理</strong></p><p>哨兵模式的主要作用在于它能够自动完成故障发现和故障转移，并通知客户端，从而实现高可用。哨兵模式通常由一组 Sentinel 节点和一组（或多组）主从复制节点组成。</p><p><strong>心跳机制</strong></p><p>（1）Sentinel与Redis Node</p><p>Redis Sentinel 是一个特殊的 Redis 节点。在哨兵模式创建时，需要通过配置指定 Sentinel 与 Redis Master Node 之间的关系，然后 Sentinel 会从主节点上获取所有从节点的信息，之后 Sentinel 会定时向主节点和从节点发送 info 命令获取其拓扑结构和状态信息。</p><p>（2）Sentinel与Sentinel</p><p>基于 Redis 的订阅发布功能， 每个 Sentinel 节点会向主节点的 <strong>sentinel</strong>：hello 频道上发送该 Sentinel 节点对于主节点的判断以及当前 Sentinel 节点的信息 ，同时每个 Sentinel 节点也会订阅该频道， 来获取其他 Sentinel 节点的信息以及它们对主节点的判断。</p><p>通过以上两步所有的 Sentinel 节点以及它们与所有的 Redis 节点之间都已经彼此感知到，之后每个 Sentinel 节点会向主节点、从节点、以及其余 Sentinel 节点定时发送 ping 命令作为心跳检测， 来确认这些节点是否可达。</p><p><strong>故障转移</strong></p><p>每个 Sentinel 都会定时进行心跳检查，当发现主节点出现心跳检测超时的情况时，此时认为该主节点已经不可用，这种判定称为<strong>主观下线</strong>。</p><p>之后该 Sentinel 节点会通过 sentinel ismaster-down-by-addr 命令向其他 Sentinel 节点询问对主节点的判断， 当 quorum（法定人数） 个 Sentinel 节点都认为该节点故障时，则执行<strong>客观下线</strong>，即认为该节点已经不可用。这也同时解释了为什么必须需要一组 Sentinel 节点，因为单个 Sentinel 节点很容易对故障状态做出误判。</p><blockquote><p>这里 quorum 的值是我们在哨兵模式搭建时指定的，后文会有说明，通常为 Sentinel节点总数/2+1，即半数以上节点做出主观下线判断就可以执行客观下线。</p></blockquote><p>因为故障转移的工作只需要一个 Sentinel 节点来完成，所以 Sentinel 节点之间会再做一次选举工作， 基于 Raft 算法选出一个 Sentinel 领导者来进行故障转移的工作。</p><p>被选举出的 Sentinel 领导者进行故障转移的具体步骤如下：</p><p>（1）在从节点列表中选出一个节点作为新的主节点</p><ul><li>过滤不健康或者不满足要求的节点；</li><li>选择 slave-priority（优先级）最高的从节点， 如果存在则返回， 不存在则继续；</li><li>选择复制偏移量最大的从节点 ， 如果存在则返回， 不存在则继续；</li><li>选择 runid 最小的从节点。</li></ul><p>（2）Sentinel 领导者节点会对选出来的从节点执行 slaveof no one 命令让其成为主节点。</p><p>（3）Sentinel 领导者节点会向剩余的从节点发送命令，让他们从新的主节点上复制数据。</p><p>（4）Sentinel 领导者会将原来的主节点更新为从节点， 并对其进行监控， 当其恢复后命令它去复制新的主节点。</p><h2 id="_15、cluster-集群-的原理你能讲一下吗" tabindex="-1"><a class="header-anchor" href="#_15、cluster-集群-的原理你能讲一下吗"><span>15、Cluster（集群）的原理你能讲一下吗？</span></a></h2><p>引入Cluster模式的原因： 不管是主从模式还是哨兵模式都只能由一个master在写数据，在海量数据高并发场景，一个节点写数据容易出现瓶颈，引入Cluster模式可以实现多个节点同时写数据。</p><p>Redis-Cluster采用无中心结构，每个节点都保存数据，节点之间互相连接从而知道整个集群状态。</p><div align="center"><img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201018222025.png" width="500"></div><br><p>如图所示Cluster模式其实就是多个主从复制的结构组合起来的，每一个主从复制结构可以看成一个节点，那么上面的Cluster集群中就有三个节点。</p><h2 id="_16、memcache与redis的区别都有哪些" tabindex="-1"><a class="header-anchor" href="#_16、memcache与redis的区别都有哪些"><span>16、Memcache与Redis的区别都有哪些？</span></a></h2><p><strong>存储方式</strong>Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。</p><p>Redis有部份存在硬盘上，这样能保证数据的持久性。</p><p><strong>数据支持类型</strong></p><p>Memcache对数据类型支持相对简单。</p><p>Redis有丰富的数据类型。</p><p><strong>使用底层模型不同</strong></p><p>它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。</p><p>Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。</p><h2 id="_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来" tabindex="-1"><a class="header-anchor" href="#_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来"><span>17、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？</span></a></h2><div class="language-plain line-numbers-mode" data-ext="plain" data-title="plain"><pre class="language-plain"><code>使用keys指令可以扫出指定模式的key列表：
keys pre*
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>这个时候面试官会追问该命令对线上业务有什么影响，直接看下一个问题。</p><h2 id="_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题" tabindex="-1"><a class="header-anchor" href="#_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题"><span>18、如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？</span></a></h2><p>redis 的单线程的。keys 指令会导致线 程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时 候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间 会比直接用 keys 指令长。</p><h2 id="_19、如果有大量的key需要设置同一时间过期-一般需要注意什么" tabindex="-1"><a class="header-anchor" href="#_19、如果有大量的key需要设置同一时间过期-一般需要注意什么"><span>19、如果有大量的key需要设置同一时间过期，一般需要注意什么？</span></a></h2><p>如果大量的key过期时间设置的过于集中，到过期的那个时间点，Redis可能会出现短暂的卡顿现象(因为redis是单线程的)。严重的话可能会导致服务器雪崩，所以我们一般在过期时间上加一个随机值，让过期时间尽量分散。</p><h2 id="_20、redis常用的客户端有哪些" tabindex="-1"><a class="header-anchor" href="#_20、redis常用的客户端有哪些"><span>20、Redis常用的客户端有哪些？</span></a></h2><p>Jedis：是老牌的Redis的Java实现客户端，提供了比较全面的Redis命令的支持。</p><p>Redisson：实现了分布式和可扩展的Java数据结构。</p><p>Lettuce：高级Redis客户端，用于线程安全同步，异步和响应使用，支持集群，Sentinel，管道和编码器。</p><p><strong>优点：</strong></p><p>Jedis：比较全面的提供了Redis的操作特性。</p><p>Redisson：促使使用者对Redis的关注分离，提供很多分布式相关操作服务，例如，分布式锁，分布式集合，可通过Redis支持延迟队列。</p><p>Lettuce：基于Netty框架的事件驱动的通信层，其方法调用是异步的。Lettuce的API是线程安全的，所以可以操   作单个Lettuce连接来完成各种操作。</p><h2 id="_21、如何保障mysql和redis的数据一致性" tabindex="-1"><a class="header-anchor" href="#_21、如何保障mysql和redis的数据一致性"><span>21、如何保障MySQL和Redis的数据一致性？</span></a></h2><p>如何保障 MySQL 和 Redis 的数据一致性？这个问题很早之前我就遇到过，但是一直没有仔细去研究，上个月看了极客的课程，有一篇文章专门有过讲解，刚好有粉丝也问我这个问题，所以感觉有必要单独出一篇。</p><p><strong>之前也看了很多相关的文章，但是感觉讲的都不好</strong>，很多文章都会去讲各种策略，比如（旁路缓存）策略、（读穿 / 写穿）策略和（写回）策略等，感觉意义真的不大，然后有的文章也只讲了部分情况，也没有告诉最优解。</p><p>我直接先抛一下结论：<strong>在满足实时性的条件下，不存在两者完全保存一致的方案，只有最终一致性方案</strong>。 根据网上的众多解决方案，总结出 6 种，直接看目录：</p><figure><img src="`+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="不好方案" tabindex="-1"><a class="header-anchor" href="#不好方案"><span>不好方案</span></a></h3><h4 id="_1-先写mysql-再写redis" tabindex="-1"><a class="header-anchor" href="#_1-先写mysql-再写redis"><span>1.先写MYSQL，再写REDIS</span></a></h4><figure><img src="'+d+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><blockquote><p>图解说明：</p><ul><li>这是一副时序图，描述请求的先后调用顺序；</li><li>橘黄色的线是请求 A，黑色的线是请求 B；</li><li>橘黄色的文字，是 MySQL 和 Redis 最终不一致的数据；</li><li>数据是从 10 更新为 11</li><li>后面所有的图，都是这个含义，不再赘述。</li></ul></blockquote><p>请求 A、B 都是先写 MySQL，然后再写 Redis，在高并发情况下，如果请求 A 在写 Redis 时卡了一会，请求 B 已经依次完成数据的更新，就会出现图中的问题。</p><p>这个图已经画的很清晰了，我就不用再去啰嗦了吧，<strong>不过这里有个前提，就是对于读请求，先去读 Redis，如果没有，再去读 DB，但是读请求不会再回写 Redis</strong>。 大白话说一下，就是读请求不会更新 Redis。</p><h4 id="_2-先写redis-再写mysql" tabindex="-1"><a class="header-anchor" href="#_2-先写redis-再写mysql"><span>2.先写REDIS，再写MYSQL</span></a></h4><figure><img src="'+c+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>同“先写 MySQL，再写 Redis”，看图可秒懂。</p><h4 id="_3-先删除-redis-再写-mysql" tabindex="-1"><a class="header-anchor" href="#_3-先删除-redis-再写-mysql"><span>3.先删除 Redis，再写 MySQL</span></a></h4><p>这幅图和上面有些不一样，前面的请求 A 和 B 都是更新请求，这里的请求 A 是更新请求，但是请求 B 是读请求，且请求 B 的读请求会回写 Redis。</p><figure><img src="'+u+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>请求 A 先删除缓存，可能因为卡顿，数据一直没有更新到 MySQL，导致两者数据不一致。</p><p>这种情况出现的概率比较大，因为请求 A 更新 MySQL 可能耗时会比较长，而请求 B 的前两步都是查询，会非常快。</p><h3 id="好的方案" tabindex="-1"><a class="header-anchor" href="#好的方案"><span>好的方案</span></a></h3><h4 id="_4-先删除-redis-再写-mysql-再删除-redis" tabindex="-1"><a class="header-anchor" href="#_4-先删除-redis-再写-mysql-再删除-redis"><span>4.先删除 Redis，再写 MySQL，再删除 Redis</span></a></h4><p>对于“先删除 Redis，再写 MySQL”，如果要解决最后的不一致问题，其实再对 Redis 重新删除即可，这个也是大家常说的“缓存双删”。</p><figure><img src="'+k+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>为了便于大家看图，对于蓝色的文字，“删除缓存 10”必须在“回写缓存10”后面，那如何才能保证一定是在后面呢？网上给出的第一个方案是，让请求 A 的最后一次删除，等待 500ms。</p><p>对于这种方案，看看就行，反正我是不会用，太 Low 了，风险也不可控。</p><p>那有没有更好的方案呢，我建议异步串行化删除，即删除请求入队列</p><figure><img src="'+g+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>异步删除对线上业务无影响，串行化处理保障并发情况下正确删除。</p><p>如果双删失败怎么办，网上有给 Redis 加一个缓存过期时间的方案，这个不敢苟同。个人建议整个重试机制，可以借助消息队列的重试机制，也可以自己整个表，记录重试次数，方法很多。</p><blockquote><p>简单小结一下：</p><ul><li>“缓存双删”不要用无脑的 sleep 500 ms；</li><li>通过消息队列的异步&amp;串行，实现最后一次缓存删除；</li><li>缓存删除失败，增加重试机制。</li></ul></blockquote><h4 id="_5-先写-mysql-再删除-redis" tabindex="-1"><a class="header-anchor" href="#_5-先写-mysql-再删除-redis"><span>5.先写 MySQL，再删除 Redis</span></a></h4><figure><img src="'+h+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>对于上面这种情况，对于第一次查询，请求 B 查询的数据是 10，但是 MySQL 的数据是 11，只存在这一次不一致的情况，对于不是强一致性要求的业务，可以容忍。（那什么情况下不能容忍呢，比如秒杀业务、库存服务等。）</p><p>当请求 B 进行第二次查询时，因为没有命中 Redis，会重新查一次 DB，然后再回写到 Reids。</p><figure><img src="'+m+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>这里需要满足 2 个条件：</p><ul><li>缓存刚好自动失效；</li><li>请求 B 从数据库查出 10，回写缓存的耗时，比请求 A 写数据库，并且删除缓存的还长。</li></ul><p>对于第二个条件，我们都知道更新 DB 肯定比查询耗时要长，所以出现这个情况的概率很小，同时满足上述条件的情况更小。</p><h4 id="_6-先写-mysql-通过-binlog-异步更新-redis" tabindex="-1"><a class="header-anchor" href="#_6-先写-mysql-通过-binlog-异步更新-redis"><span>6.先写 MySQL，通过 Binlog，异步更新 Redis</span></a></h4><p>这种方案，主要是监听 MySQL 的 Binlog，然后通过异步的方式，将数据更新到 Redis，这种方案有个前提，查询的请求，不会回写 Redis。</p><figure><img src="'+v+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>这个方案，会保证 MySQL 和 Redis 的最终一致性，但是如果中途请求 B 需要查询数据，如果缓存无数据，就直接查 DB；如果缓存有数据，查询的数据也会存在不一致的情况。</p><p><strong>所以这个方案，是实现最终一致性的终极解决方案，但是不能保证实时性。</strong></p><h3 id="几种方案比较" tabindex="-1"><a class="header-anchor" href="#几种方案比较"><span>几种方案比较</span></a></h3><p>我们对比上面讨论的 6 种方案：</p><h4 id="_1-先写-redis-再写-mysql" tabindex="-1"><a class="header-anchor" href="#_1-先写-redis-再写-mysql"><span>1.先写 Redis，再写 MySQL</span></a></h4><ul><li>这种方案，我肯定不会用，万一 DB 挂了，你把数据写到缓存，DB 无数据，这个是灾难性的；</li><li>我之前也见同学这么用过，如果写 DB 失败，对 Redis 进行逆操作，那如果逆操作失败呢，是不是还要搞个重试？</li></ul><h4 id="_2-先写-mysql-再写-redis" tabindex="-1"><a class="header-anchor" href="#_2-先写-mysql-再写-redis"><span>2.先写 MySQL，再写 Redis</span></a></h4><ul><li>对于并发量、一致性要求不高的项目，很多就是这么用的，我之前也经常这么搞，但是不建议这么做；</li><li>当 Redis 瞬间不可用的情况，需要报警出来，然后线下处理。</li></ul><h4 id="_3-先删除-redis-再写-mysql-1" tabindex="-1"><a class="header-anchor" href="#_3-先删除-redis-再写-mysql-1"><span>3.先删除 Redis，再写 MySQL</span></a></h4><ul><li>这种方式，我还真没用过，直接忽略吧。</li></ul><h4 id="_4-先删除-redis-再写-mysql-再删除-redis-1" tabindex="-1"><a class="header-anchor" href="#_4-先删除-redis-再写-mysql-再删除-redis-1"><span>4.先删除 Redis，再写 MySQL，再删除 Redis</span></a></h4><ul><li>这种方式虽然可行，但是感觉好复杂，还要搞个消息队列去异步删除 Redis。</li></ul><h4 id="_5-先写-mysql-再删除-redis-1" tabindex="-1"><a class="header-anchor" href="#_5-先写-mysql-再删除-redis-1"><span>5.先写 MySQL，再删除 Redis</span></a></h4><ul><li>比较推荐这种方式，删除 Redis 如果失败，可以再多重试几次，否则报警出来；</li><li>这个方案，是实时性中最好的方案，在一些高并发场景中，推荐这种。</li></ul><h4 id="_6-先写-mysql-通过-binlog-异步更新-redis-1" tabindex="-1"><a class="header-anchor" href="#_6-先写-mysql-通过-binlog-异步更新-redis-1"><span>6.先写 MySQL，通过 Binlog，异步更新 Redis</span></a></h4><ul><li>对于异地容灾、数据汇总等，建议会用这种方式，比如 binlog + kafka，数据的一致性也可以达到秒级；</li><li>纯粹的高并发场景，不建议用这种方案，比如抢购、秒杀等。</li></ul><h3 id="个人结论" tabindex="-1"><a class="header-anchor" href="#个人结论"><span>个人结论：</span></a></h3><ul><li><p>实时一致性方案：采用“先写 MySQL，再删除 Redis”的策略，这种情况虽然也会存在两者不一致，但是需要满足的条件有点苛刻，所以是满足实时性条件下，能尽量满足一致性的最优解。</p></li><li><p>最终一致性方案：采用“先写 MySQL，通过 Binlog，异步更新 Redis”，可以通过 Binlog，结合消息队列异步更新 Redis，是最终一致性的最优解。</p></li></ul><h2 id="_22-分布式锁及实现方案" tabindex="-1"><a class="header-anchor" href="#_22-分布式锁及实现方案"><span>22. 分布式锁及实现方案</span></a></h2><h3 id="什么是分布式锁" tabindex="-1"><a class="header-anchor" href="#什么是分布式锁"><span>什么是分布式锁</span></a></h3><blockquote><p>要介绍分布式锁，首先要提到与分布式锁相对应的是线程锁、进程锁。</p></blockquote><ul><li><p><strong>线程锁</strong>：主要用来给方法、代码块加锁。当某个方法或代码使用锁，在同一时刻仅有一个线程执行该方法或该代码段。线程锁只在同一JVM中有效果，因为线程锁的实现在根本上是依靠线程之间共享内存实现的，比如synchronized是共享对象头，显示锁Lock是 共享某个变量（state）。</p></li><li><p><strong>进程锁</strong>：为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过synchronized等线程锁实现进程锁。</p></li><li><p><strong>分布式锁</strong>：当多个进程不在同一个系统中(比如分布式系统中控制共享资源访问)，用分布式锁控制多个进程对资源的访问。</p></li></ul><h3 id="分布式锁的设计原则" tabindex="-1"><a class="header-anchor" href="#分布式锁的设计原则"><span>分布式锁的设计原则</span></a></h3><blockquote><p>分布式锁的最小设计原则：安全性和有效性</p></blockquote><p>Redis的官网对使用分布式锁提出至少需要满足如下三个要求：</p><ul><li>互斥（属于安全性）：在任何给定时刻，只有一个客户端可以持有锁。</li><li>无死锁（属于有效性）：即使锁定资源的客户端崩溃或被分区，也总是可以获得锁；通常通过超时机制实现。</li><li>容错性（属于有效性）：只要大多数 Redis 节点都启动，客户端就可以获取和释放锁。</li></ul><p>除此之外，分布式锁的设计中还可以/需要考虑：</p><ul><li>加锁解锁的同源性：A加的锁，不能被B解锁</li><li>获取锁是非阻塞的：如果获取不到锁，不能无限期等待；</li><li>高性能：加锁解锁是高性能的</li></ul><h3 id="分布式锁的实现方案" tabindex="-1"><a class="header-anchor" href="#分布式锁的实现方案"><span>分布式锁的实现方案</span></a></h3><blockquote><p>就体系的角度而言，谈谈常见的分布式锁的实现方案。</p></blockquote><ul><li>基于数据库实现分布式锁 <ul><li>基于数据库表（锁表，很少使用）</li><li>乐观锁(基于版本号)</li><li>悲观锁(基于排它锁)基于</li></ul></li><li>redis 实现分布式锁 <ul><li>单个Redis实例：setnx(key,当前时间+过期时间) + LuaRedis</li><li>集群模式：Redlock</li></ul></li><li>基于 zookeeper实现分布式锁 <ul><li>临时有序节点来实现的分布式锁</li></ul></li><li>基于 Consul 实现分布式锁</li></ul><h3 id="基于数据库如何实现分布式锁-有什么缺陷" tabindex="-1"><a class="header-anchor" href="#基于数据库如何实现分布式锁-有什么缺陷"><span>基于数据库如何实现分布式锁？有什么缺陷？</span></a></h3><h4 id="_1-基于数据库表-锁表-很少使用" tabindex="-1"><a class="header-anchor" href="#_1-基于数据库表-锁表-很少使用"><span>1.基于数据库表（锁表，很少使用）</span></a></h4><p>最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。 当我们想要获得锁的时候，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录。 为了更好的演示，我们先创建一张数据库表，参考如下:</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> database_lock <span class="token punctuation">(</span>
	<span class="token identifier"><span class="token punctuation">\`</span>id<span class="token punctuation">\`</span></span> <span class="token keyword">BIGINT</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">AUTO_INCREMENT</span><span class="token punctuation">,</span>
	<span class="token identifier"><span class="token punctuation">\`</span>resource<span class="token punctuation">\`</span></span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">COMMENT</span> <span class="token string">&#39;锁定的资源&#39;</span><span class="token punctuation">,</span>
	<span class="token identifier"><span class="token punctuation">\`</span>description<span class="token punctuation">\`</span></span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token string">&quot;&quot;</span> <span class="token keyword">COMMENT</span> <span class="token string">&#39;描述&#39;</span><span class="token punctuation">,</span>
	<span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">,</span>
	<span class="token keyword">UNIQUE</span> <span class="token keyword">KEY</span> uiq_idx_resource <span class="token punctuation">(</span>resource<span class="token punctuation">)</span>
<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8mb4 <span class="token keyword">COMMENT</span><span class="token operator">=</span><span class="token string">&#39;数据库分布式锁表&#39;</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>当我们想要获得锁时，可以插入一条数据：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> database_lock<span class="token punctuation">(</span>resource<span class="token punctuation">,</span> description<span class="token punctuation">)</span> <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">&#39;lock&#39;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>当需要释放锁的时，可以删除这条数据：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">DELETE</span> <span class="token keyword">FROM</span> database_lock <span class="token keyword">WHERE</span> resource<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="_2-基于悲观锁" tabindex="-1"><a class="header-anchor" href="#_2-基于悲观锁"><span>2.基于悲观锁</span></a></h4><ul><li><strong>悲观锁实现思路？</strong></li></ul><ol><li>在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。</li><li>如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。</li><li>如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。</li><li>其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。</li></ol><ul><li><strong>以MySQL InnoDB中使用悲观锁为例？</strong></li></ul><p>要使用悲观锁，我们必须关闭mysql数据库的自动提交属性，因为MySQL默认使用<code>autocommit</code>模式，也就是说，当你执行一个更新操作后，MySQL会立刻将结果进行提交。<code>set autocommit=0</code>;</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token comment">//0.开始事务</span>
<span class="token keyword">begin</span><span class="token punctuation">;</span><span class="token operator">/</span><span class="token keyword">begin</span> <span class="token keyword">work</span><span class="token punctuation">;</span><span class="token operator">/</span><span class="token keyword">start</span> <span class="token keyword">transaction</span><span class="token punctuation">;</span> <span class="token punctuation">(</span>三者选一就可以<span class="token punctuation">)</span>
<span class="token comment">//1.查询出商品信息</span>
<span class="token keyword">select</span> <span class="token keyword">status</span> <span class="token keyword">from</span> t_goods <span class="token keyword">where</span> id<span class="token operator">=</span><span class="token number">1</span> <span class="token keyword">for</span> <span class="token keyword">update</span><span class="token punctuation">;</span>
<span class="token comment">//2.根据商品信息生成订单</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> t_orders <span class="token punctuation">(</span>id<span class="token punctuation">,</span>goods_id<span class="token punctuation">)</span> <span class="token keyword">values</span> <span class="token punctuation">(</span><span class="token boolean">null</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">//3.修改商品status为2</span>
<span class="token keyword">update</span> t_goods <span class="token keyword">set</span> <span class="token keyword">status</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">;</span>
<span class="token comment">//4.提交事务</span>
<span class="token keyword">commit</span><span class="token punctuation">;</span><span class="token operator">/</span><span class="token keyword">commit</span> <span class="token keyword">work</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面的查询语句中，我们使用了select…for update的方式，这样就通过开启排他锁的方式实现了悲观锁。此时在t_goods表中，id为1的 那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。这样我们可以保证当前的数据不会被其它事务修改。</p><p>上面我们提到，使用select…for update会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。</p><h4 id="_3-基于乐观锁" tabindex="-1"><a class="header-anchor" href="#_3-基于乐观锁"><span>3.基于乐观锁</span></a></h4><p>乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。</p><ul><li><strong>以使用版本号实现乐观锁为例？</strong></li></ul><p>使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token number">1.</span>查询出商品信息
<span class="token keyword">select</span> <span class="token punctuation">(</span><span class="token keyword">status</span><span class="token punctuation">,</span><span class="token keyword">status</span><span class="token punctuation">,</span>version<span class="token punctuation">)</span> <span class="token keyword">from</span> t_goods <span class="token keyword">where</span> id<span class="token operator">=</span><span class="token comment">#{id}</span>
<span class="token number">2.</span>根据商品信息生成订单
<span class="token number">3.</span>修改商品<span class="token keyword">status</span>为<span class="token number">2</span>
<span class="token keyword">update</span> t_goods 
<span class="token keyword">set</span> <span class="token keyword">status</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>version<span class="token operator">=</span>version<span class="token operator">+</span><span class="token number">1</span>
<span class="token keyword">where</span> id<span class="token operator">=</span><span class="token comment">#{id} and version=#{version};</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>需要注意的是，乐观锁机制往往基于系统中数据存储逻辑，因此也具备一定的局限性。 由于乐观锁机制是在我们的系统中实现的，对于来自外部系统的用户数据更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。 在系统设计阶段，我们应该充分考虑到这些情况，并进行相应的调整（如将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。</p><ul><li><strong>缺陷</strong></li></ul><p>对数据库依赖，开销问题，行锁变表锁问题，无法解决数据库单点和可重入的问题</p><h3 id="基于redis如何实现分布式锁-有什么缺陷" tabindex="-1"><a class="header-anchor" href="#基于redis如何实现分布式锁-有什么缺陷"><span>基于redis如何实现分布式锁？有什么缺陷？</span></a></h3><h4 id="set-nx-px-lua" tabindex="-1"><a class="header-anchor" href="#set-nx-px-lua"><span>set NX PX + Lua</span></a></h4><ul><li><strong>加锁: set NX PX + 重试 + 重试间隔</strong></li></ul><p>向Redis发起如下命令: <code>SET productId:lock 0xx9p03001 NX PX 30000</code> 其中，<code>&quot;productId&quot;</code>由自己定义，可以是与本次业务有关的id，<code>&quot;0xx9p03001&quot;</code>是一串随机值，必须保证全局唯一(原因在后文中会提到)，<code>“NX&quot;</code>指的是当且仅当key(也就是案例中的<code>&quot;productId:lock”</code>)在Redis中不存在时，返回执行成功，否则执行失败。<code>&quot;PX 30000&quot;</code>指的是在30秒后，key将被自动删除。执行命令后返回成功，表明服务成功的获得了锁。</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token annotation punctuation">@Override</span>
<span class="token keyword">public</span> <span class="token keyword">boolean</span> <span class="token function">lock</span><span class="token punctuation">(</span><span class="token class-name">String</span> key<span class="token punctuation">,</span> <span class="token keyword">long</span> expire<span class="token punctuation">,</span> <span class="token keyword">int</span> retryTimes<span class="token punctuation">,</span> <span class="token keyword">long</span> retryDuration<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// use JedisCommands instead of setIfAbsense</span>
    <span class="token keyword">boolean</span> result <span class="token operator">=</span> <span class="token function">setRedis</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> expire<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// retry if needed</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">!</span>result<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> retryTimes<span class="token operator">--</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            log<span class="token punctuation">.</span><span class="token function">debug</span><span class="token punctuation">(</span><span class="token string">&quot;lock failed, retrying...&quot;</span> <span class="token operator">+</span> retryTimes<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span>retryDuration<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// use JedisCommands instead of setIfAbsense</span>
        result <span class="token operator">=</span> <span class="token function">setRedis</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> expire<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> result<span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">private</span> <span class="token keyword">boolean</span> <span class="token function">setRedis</span><span class="token punctuation">(</span><span class="token class-name">String</span> key<span class="token punctuation">,</span> <span class="token keyword">long</span> expire<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
        <span class="token class-name">RedisCallback</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> redisCallback <span class="token operator">=</span> connection <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
            <span class="token class-name">JedisCommands</span> commands <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token class-name">JedisCommands</span><span class="token punctuation">)</span> connection<span class="token punctuation">.</span><span class="token function">getNativeConnection</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token class-name">String</span> uuid <span class="token operator">=</span> <span class="token class-name">SnowIDUtil</span><span class="token punctuation">.</span><span class="token function">uniqueStr</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            lockFlag<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>uuid<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> commands<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> uuid<span class="token punctuation">,</span> <span class="token constant">NX</span><span class="token punctuation">,</span> <span class="token constant">PX</span><span class="token punctuation">,</span> expire<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 看这里</span>
        <span class="token punctuation">}</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> result <span class="token operator">=</span> redisTemplate<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span>redisCallback<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> <span class="token operator">!</span><span class="token class-name">StringUtil</span><span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        log<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">&quot;set redis occurred an exception&quot;</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>解锁: 采用lua脚本</strong></li></ul><p>在删除key之前，一定要判断服务A持有的value与Redis内存储的value是否一致。如果贸然使用服务A持有的key来删除锁，则会误将服务B的锁释放掉。</p><div class="language-lua line-numbers-mode" data-ext="lua" data-title="lua"><pre class="language-lua"><code><span class="token keyword">if</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&quot;get&quot;</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">==</span>ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">then</span>
	<span class="token keyword">return</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&quot;del&quot;</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">else</span>
	<span class="token keyword">return</span> <span class="token number">0</span>
<span class="token keyword">end</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="基于redlock实现分布式锁" tabindex="-1"><a class="header-anchor" href="#基于redlock实现分布式锁"><span>基于RedLock实现分布式锁</span></a></h4><p>假设有两个服务A、B都希望获得锁，有一个包含了5个redis master的Redis Cluster，执行过程大致如下:</p><ol><li>客户端获取当前时间戳，单位: 毫秒</li><li>服务A轮寻每个master节点，尝试创建锁。(这里锁的过期时间比较短，一般就几十毫秒) RedLock算法会尝试在大多数节点上分别创建锁，假如节点总数为n，那么大多数节点指的是n/2+1。</li><li>客户端计算成功建立完锁的时间，如果建锁时间小于超时时间，就可以判定锁创建成功。如果锁创建失败，则依次(遍历master节点)删除锁。</li><li>只要有其它服务创建过分布式锁，那么当前服务就必须轮寻尝试获取锁</li></ol><h4 id="基于redis的客户端" tabindex="-1"><a class="header-anchor" href="#基于redis的客户端"><span>基于Redis的客户端</span></a></h4><blockquote><p>这里Redis的客户端（Jedis, Redisson, Lettuce等）都是基于上述两类形式来实现分布式锁的，只是两类形式的封装以及一些优化（比如Redisson的watch dog)。</p></blockquote><p>以基于Redisson实现分布式锁为例（支持了 单实例、Redis哨兵、redis cluster、redis master-slave等各种部署架构）：</p><p><strong>特色？</strong></p><ul><li><p>redisson所有指令都通过lua脚本执行，保证了操作的原子性</p></li><li><p>redisson设置了watchdog看门狗，“看门狗”的逻辑保证了没有死锁发生</p></li><li><p>redisson支持Redlock的实现方式。</p></li><li><p><strong>过程？</strong></p></li><li><p>线程去获取锁，获取成功: 执行lua脚本，保存数据到redis数据库。</p></li><li><p>线程去获取锁，获取失败: 订阅了解锁消息，然后再尝试获取锁，获取成功后，执行lua脚本，保存数据到redis数据库。</p></li></ul><p><strong>互斥？</strong></p><p>如果这个时候客户端B来尝试加锁，执行了同样的一段lua脚本。第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在。接着第二个if判断，判断myLock锁key的hash数据结构中，是否包含客户端B的ID，但明显没有，那么客户端B会获取到pttl myLock返回的一个数字，代表myLock这个锁key的剩余生存时间。此时客户端B会进入一个while循环，不听的尝试加锁。</p><p><strong>watch dog自动延时机制</strong>​</p><p>客户端A加锁的锁key默认生存时间只有30秒，如果超过了30秒，客户端A还想一直持有这把锁，怎么办？其实只要客户端A一旦加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间。</p><p><strong>可重入？</strong></p><p>每次lock会调用incrby，每次unlock会减一。</p><h4 id="进一步理解" tabindex="-1"><a class="header-anchor" href="#进一步理解"><span>进一步理解</span></a></h4><ul><li>借助Redis实现分布式锁时，有一个共同的缺陷: 当获取锁被拒绝后，需要不断的循环，重新发送获取锁(创建key)的请求，直到请求成功。这就造成空转，浪费宝贵的CPU资源。</li><li>RedLock算法本身有争议，具体看这篇文章How to do distributed locking在新窗口打开 以及作者的回复Is Redlock safe?</li></ul><h3 id="基于zookeeper如何实现分布式锁" tabindex="-1"><a class="header-anchor" href="#基于zookeeper如何实现分布式锁"><span>基于zookeeper如何实现分布式锁？</span></a></h3><p>说几个核心点：</p><ul><li><strong>顺序节点</strong></li></ul><p>创建一个用于发号的节点“/test/lock”，然后以它为父亲节点的前缀为“/test/lock/seq-” 依次发号：</p><figure><img src="`+y+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><strong>获得最小号得锁</strong></li></ul><p>由于序号的递增性，可以规定排号最小的那个获得锁。所以，每个线程在尝试占用锁之前，首先判断自己是排号是不是当前最小，如果是，则获取锁。</p><ul><li><strong>节点监听机制</strong></li></ul><p>每个线程抢占锁之前，先抢号创建自己的ZNode。同样，释放锁的时候，就需要删除抢号的Znode。抢号成功后，如果不是排号最小的节点，就处于等待通知的状态。等谁的通知呢？不需要其他人，只需要等前一个Znode 的通知就可以了。当前一个Znode 删除的时候，就是轮到了自己占有锁的时候。第一个通知第二个、第二个通知第三个，击鼓传花似的依次向后。</p>',496);function x(A,S){const a=t("ExternalLinkIcon");return p(),l("div",null,[R,n("p",null,[s("查询官方文档（"),n("a",f,[s("https://redis.io/topics/data-types"),o(a)]),s("）可以看到String类型的value值最多支持的长度为512M，所以正确的答案是512M。")]),_])}const q=i(b,[["render",x],["__file","index.html.vue"]]),O=JSON.parse('{"path":"/interview/redis/","title":"REDIS知识点","lang":"en-US","frontmatter":{"icon":"home","toc":true,"sidebar":false},"headers":[{"level":2,"title":"1、什么是Redis，Redis有哪些特点？","slug":"_1、什么是redis-redis有哪些特点","link":"#_1、什么是redis-redis有哪些特点","children":[]},{"level":2,"title":"2、Redis有哪些数据结构？","slug":"_2、redis有哪些数据结构","link":"#_2、redis有哪些数据结构","children":[]},{"level":2,"title":"3、一个字符串类型的值能存储最大容量是多少？","slug":"_3、一个字符串类型的值能存储最大容量是多少","link":"#_3、一个字符串类型的值能存储最大容量是多少","children":[]},{"level":2,"title":"4、能说一下Redis每种数据结构的使用场景吗？","slug":"_4、能说一下redis每种数据结构的使用场景吗","link":"#_4、能说一下redis每种数据结构的使用场景吗","children":[]},{"level":2,"title":"5、Redis如何做持久化的?能说一下RDB和AOF的实现原理吗?","slug":"_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗","link":"#_5、redis如何做持久化的-能说一下rdb和aof的实现原理吗","children":[{"level":3,"title":"RDB持久化","slug":"rdb持久化","link":"#rdb持久化","children":[]},{"level":3,"title":"AOF持久化","slug":"aof持久化","link":"#aof持久化","children":[]},{"level":3,"title":"RDB和AOF的优缺点","slug":"rdb和aof的优缺点","link":"#rdb和aof的优缺点","children":[]}]},{"level":2,"title":"6、讲解一下Redis的线程模型？","slug":"_6、讲解一下redis的线程模型","link":"#_6、讲解一下redis的线程模型","children":[]},{"level":2,"title":"7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么？","slug":"_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么","link":"#_7、缓存雪崩、缓存穿透、缓存预热、缓存击穿、缓存降级的区别是什么","children":[{"level":3,"title":"（1）缓存穿透","slug":"_1-缓存穿透","link":"#_1-缓存穿透","children":[]},{"level":3,"title":"（2）缓存击穿","slug":"_2-缓存击穿","link":"#_2-缓存击穿","children":[]},{"level":3,"title":"（3）缓存雪崩","slug":"_3-缓存雪崩","link":"#_3-缓存雪崩","children":[]},{"level":3,"title":"（4）缓存预热","slug":"_4-缓存预热","link":"#_4-缓存预热","children":[]},{"level":3,"title":"（5）缓存降级","slug":"_5-缓存降级","link":"#_5-缓存降级","children":[]}]},{"level":2,"title":"8、Redis的内存淘汰机制","slug":"_8、redis的内存淘汰机制","link":"#_8、redis的内存淘汰机制","children":[]},{"level":2,"title":"9、Redis有事务机制吗？","slug":"_9、redis有事务机制吗","link":"#_9、redis有事务机制吗","children":[]},{"level":2,"title":"10、Redis事务到底是不是原子性的？","slug":"_10、redis事务到底是不是原子性的","link":"#_10、redis事务到底是不是原子性的","children":[]},{"level":2,"title":"11、Redis为什么不支持回滚（roll back）？","slug":"_11、redis为什么不支持回滚-roll-back","link":"#_11、redis为什么不支持回滚-roll-back","children":[]},{"level":2,"title":"12、Redis事务相关的命令有哪几个？","slug":"_12、redis事务相关的命令有哪几个","link":"#_12、redis事务相关的命令有哪几个","children":[]},{"level":2,"title":"13、什么是Redis主从复制？","slug":"_13、什么是redis主从复制","link":"#_13、什么是redis主从复制","children":[]},{"level":2,"title":"14、Sentinel（哨兵模式）的原理你能讲一下吗？","slug":"_14、sentinel-哨兵模式-的原理你能讲一下吗","link":"#_14、sentinel-哨兵模式-的原理你能讲一下吗","children":[]},{"level":2,"title":"15、Cluster（集群）的原理你能讲一下吗？","slug":"_15、cluster-集群-的原理你能讲一下吗","link":"#_15、cluster-集群-的原理你能讲一下吗","children":[]},{"level":2,"title":"16、Memcache与Redis的区别都有哪些？","slug":"_16、memcache与redis的区别都有哪些","link":"#_16、memcache与redis的区别都有哪些","children":[]},{"level":2,"title":"17、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？","slug":"_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来","link":"#_17、假如redis里面有1亿个key-其中有10w个key是以某个固定的已知的前缀开头的-如果将它们全部找出来","children":[]},{"level":2,"title":"18、如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？","slug":"_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题","link":"#_18、如果这个redis正在给线上的业务提供服务-那使用keys指令会有什么问题","children":[]},{"level":2,"title":"19、如果有大量的key需要设置同一时间过期，一般需要注意什么？","slug":"_19、如果有大量的key需要设置同一时间过期-一般需要注意什么","link":"#_19、如果有大量的key需要设置同一时间过期-一般需要注意什么","children":[]},{"level":2,"title":"20、Redis常用的客户端有哪些？","slug":"_20、redis常用的客户端有哪些","link":"#_20、redis常用的客户端有哪些","children":[]},{"level":2,"title":"21、如何保障MySQL和Redis的数据一致性？","slug":"_21、如何保障mysql和redis的数据一致性","link":"#_21、如何保障mysql和redis的数据一致性","children":[{"level":3,"title":"不好方案","slug":"不好方案","link":"#不好方案","children":[]},{"level":3,"title":"好的方案","slug":"好的方案","link":"#好的方案","children":[]},{"level":3,"title":"几种方案比较","slug":"几种方案比较","link":"#几种方案比较","children":[]},{"level":3,"title":"个人结论：","slug":"个人结论","link":"#个人结论","children":[]}]},{"level":2,"title":"22. 分布式锁及实现方案","slug":"_22-分布式锁及实现方案","link":"#_22-分布式锁及实现方案","children":[{"level":3,"title":"什么是分布式锁","slug":"什么是分布式锁","link":"#什么是分布式锁","children":[]},{"level":3,"title":"分布式锁的设计原则","slug":"分布式锁的设计原则","link":"#分布式锁的设计原则","children":[]},{"level":3,"title":"分布式锁的实现方案","slug":"分布式锁的实现方案","link":"#分布式锁的实现方案","children":[]},{"level":3,"title":"基于数据库如何实现分布式锁？有什么缺陷？","slug":"基于数据库如何实现分布式锁-有什么缺陷","link":"#基于数据库如何实现分布式锁-有什么缺陷","children":[]},{"level":3,"title":"基于redis如何实现分布式锁？有什么缺陷？","slug":"基于redis如何实现分布式锁-有什么缺陷","link":"#基于redis如何实现分布式锁-有什么缺陷","children":[]},{"level":3,"title":"基于zookeeper如何实现分布式锁？","slug":"基于zookeeper如何实现分布式锁","link":"#基于zookeeper如何实现分布式锁","children":[]}]}],"git":{"createdTime":1728465902000,"updatedTime":1728836576000,"contributors":[{"name":"George","email":"leiping@yunxianginvest.com","commits":2},{"name":"leiping","email":"leiping@91cyt.com","commits":2}]},"readingTime":{"minutes":63.63,"words":19090},"filePathRelative":"interview/redis/README.md","localizedDate":"October 9, 2024","excerpt":"\\n<h2>1、什么是Redis，Redis有哪些特点？</h2>\\n<p>Redis全称为：Remote Dictionary&nbsp;Server（远程数据服务），Redis是一种支持key-value等多种数据结构的存储系统。\\n可用于<strong>缓存</strong>，<strong>事件发布或订阅</strong>，<strong>高速队列</strong>等场景。支持网络，提供<strong>字符串</strong>，<strong>哈希</strong>，<strong>列表</strong>，<strong>队列</strong>，<strong>集合</strong>结构直接存取，基于内存，可持久化。</p>"}');export{q as comp,O as data};
